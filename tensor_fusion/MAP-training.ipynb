{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5f4897-7608-414a-8887-ab5ad2bbaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datasets import Multimodal_Binary_Dataset\n",
    "from fusion_model import CP_Tensor_Fusion_Network\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d2c45b9-5fd9-48b5-b441-cab6251d961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cmu_mosi(batch_size=32, epochs=100, lr=.001, max_rank=20, rank_adaptive=True,  \n",
    "                   warmup_epochs=50, kl_multiplier=1e-4, no_kl_epochs=5, accelerated=True):\n",
    "\n",
    "    # load dataset file\n",
    "    file = open('../../dataset/cmu-mosi/mosi_20_seq_data.pkl', 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # prepare the datasets and data loaders\n",
    "    train_set = Multimodal_Binary_Dataset(data['train']['text'], data['train']['audio'],\n",
    "                                  data['train']['vision'], data['train']['labels'])\n",
    "    valid_set = Multimodal_Binary_Dataset(data['valid']['text'], data['valid']['audio'],\n",
    "                                  data['valid']['vision'], data['valid']['labels'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "\n",
    "    # set up model\n",
    "    input_sizes = (train_set[0][0]['audio'].shape[0], train_set[0][0]['vision'].shape[0],\n",
    "                   train_set[0][0]['text'].shape[1])\n",
    "    hidden_sizes = (32, 32, 128)\n",
    "    output_size = 1\n",
    "    \n",
    "    model = CP_Tensor_Fusion_Network(input_sizes, hidden_sizes, output_size, max_rank,\n",
    "                                     rank_adaptive)\n",
    "    # set up training\n",
    "    DTYPE = torch.FloatTensor\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # train and validate\n",
    "    for e in range(1, epochs + 1):\n",
    "        # train\n",
    "        tic = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            features, label = batch\n",
    "            \n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            \n",
    "            output = model([x_a, x_v, x_t])\n",
    "            nll_loss = criterion(output, y)\n",
    "            nlp_loss = get_neg_log_prior_loss(model.tensor_fusion_layer.weight_tensor.rank_parameter,\n",
    "                                              model.tensor_fusion_layer.weight_tensor.factors)\n",
    "\n",
    "            nll_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += nll_loss.item()\n",
    "        \n",
    "        return model\n",
    "        print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2de2191-0bef-42d0-ad08-e26e66bf1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_log_prior_loss(rank_parameter, factors):\n",
    "    dist = td.Normal(0, rank_parameter)\n",
    "    for factor in factors:\n",
    "        p = -torch.sum(torch.log(dist.cdf(factor)))\n",
    "        print(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a1b21b4-63e2-4d99-9dc6-485a33647532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(644.1651, grad_fn=<NegBackward>)\n",
      "tensor(621.0089, grad_fn=<NegBackward>)\n",
      "tensor(2558.0603, grad_fn=<NegBackward>)\n",
      "tensor(18.5479, grad_fn=<NegBackward>)\n",
      "tensor(644.5923, grad_fn=<NegBackward>)\n",
      "tensor(621.0871, grad_fn=<NegBackward>)\n",
      "tensor(2557.8948, grad_fn=<NegBackward>)\n",
      "tensor(18.5685, grad_fn=<NegBackward>)\n",
      "tensor(644.6938, grad_fn=<NegBackward>)\n",
      "tensor(621.0804, grad_fn=<NegBackward>)\n",
      "tensor(2557.6550, grad_fn=<NegBackward>)\n",
      "tensor(18.5952, grad_fn=<NegBackward>)\n",
      "tensor(644.5192, grad_fn=<NegBackward>)\n",
      "tensor(620.9665, grad_fn=<NegBackward>)\n",
      "tensor(2557.5671, grad_fn=<NegBackward>)\n",
      "tensor(18.6205, grad_fn=<NegBackward>)\n",
      "tensor(644.5486, grad_fn=<NegBackward>)\n",
      "tensor(620.8978, grad_fn=<NegBackward>)\n",
      "tensor(2557.4680, grad_fn=<NegBackward>)\n",
      "tensor(18.6370, grad_fn=<NegBackward>)\n",
      "tensor(644.6428, grad_fn=<NegBackward>)\n",
      "tensor(620.8658, grad_fn=<NegBackward>)\n",
      "tensor(2557.3743, grad_fn=<NegBackward>)\n",
      "tensor(18.6571, grad_fn=<NegBackward>)\n",
      "tensor(644.5530, grad_fn=<NegBackward>)\n",
      "tensor(620.8603, grad_fn=<NegBackward>)\n",
      "tensor(2557.3574, grad_fn=<NegBackward>)\n",
      "tensor(18.6773, grad_fn=<NegBackward>)\n",
      "tensor(644.3947, grad_fn=<NegBackward>)\n",
      "tensor(620.8902, grad_fn=<NegBackward>)\n",
      "tensor(2557.3306, grad_fn=<NegBackward>)\n",
      "tensor(18.6940, grad_fn=<NegBackward>)\n",
      "tensor(644.1446, grad_fn=<NegBackward>)\n",
      "tensor(620.9216, grad_fn=<NegBackward>)\n",
      "tensor(2557.3337, grad_fn=<NegBackward>)\n",
      "tensor(18.7195, grad_fn=<NegBackward>)\n",
      "tensor(643.8750, grad_fn=<NegBackward>)\n",
      "tensor(620.9138, grad_fn=<NegBackward>)\n",
      "tensor(2557.3335, grad_fn=<NegBackward>)\n",
      "tensor(18.7519, grad_fn=<NegBackward>)\n",
      "tensor(643.5714, grad_fn=<NegBackward>)\n",
      "tensor(620.8612, grad_fn=<NegBackward>)\n",
      "tensor(2557.3215, grad_fn=<NegBackward>)\n",
      "tensor(18.7653, grad_fn=<NegBackward>)\n",
      "tensor(643.3994, grad_fn=<NegBackward>)\n",
      "tensor(620.9042, grad_fn=<NegBackward>)\n",
      "tensor(2557.2842, grad_fn=<NegBackward>)\n",
      "tensor(18.7626, grad_fn=<NegBackward>)\n",
      "tensor(643.2114, grad_fn=<NegBackward>)\n",
      "tensor(620.9147, grad_fn=<NegBackward>)\n",
      "tensor(2557.2505, grad_fn=<NegBackward>)\n",
      "tensor(18.7593, grad_fn=<NegBackward>)\n",
      "tensor(642.9948, grad_fn=<NegBackward>)\n",
      "tensor(620.9287, grad_fn=<NegBackward>)\n",
      "tensor(2557.1914, grad_fn=<NegBackward>)\n",
      "tensor(18.7556, grad_fn=<NegBackward>)\n",
      "tensor(642.8137, grad_fn=<NegBackward>)\n",
      "tensor(620.9543, grad_fn=<NegBackward>)\n",
      "tensor(2557.1492, grad_fn=<NegBackward>)\n",
      "tensor(18.7594, grad_fn=<NegBackward>)\n",
      "tensor(642.5723, grad_fn=<NegBackward>)\n",
      "tensor(620.9956, grad_fn=<NegBackward>)\n",
      "tensor(2557.1462, grad_fn=<NegBackward>)\n",
      "tensor(18.7714, grad_fn=<NegBackward>)\n",
      "tensor(642.2828, grad_fn=<NegBackward>)\n",
      "tensor(621.0313, grad_fn=<NegBackward>)\n",
      "tensor(2557.1284, grad_fn=<NegBackward>)\n",
      "tensor(18.7871, grad_fn=<NegBackward>)\n",
      "tensor(642.0690, grad_fn=<NegBackward>)\n",
      "tensor(621.0463, grad_fn=<NegBackward>)\n",
      "tensor(2557.1101, grad_fn=<NegBackward>)\n",
      "tensor(18.8021, grad_fn=<NegBackward>)\n",
      "tensor(641.8152, grad_fn=<NegBackward>)\n",
      "tensor(621.0485, grad_fn=<NegBackward>)\n",
      "tensor(2557.0942, grad_fn=<NegBackward>)\n",
      "tensor(18.8133, grad_fn=<NegBackward>)\n",
      "tensor(641.6080, grad_fn=<NegBackward>)\n",
      "tensor(621.0469, grad_fn=<NegBackward>)\n",
      "tensor(2557.0862, grad_fn=<NegBackward>)\n",
      "tensor(18.8262, grad_fn=<NegBackward>)\n",
      "tensor(641.4261, grad_fn=<NegBackward>)\n",
      "tensor(621.0039, grad_fn=<NegBackward>)\n",
      "tensor(2557.0881, grad_fn=<NegBackward>)\n",
      "tensor(18.8398, grad_fn=<NegBackward>)\n",
      "tensor(641.4266, grad_fn=<NegBackward>)\n",
      "tensor(620.9813, grad_fn=<NegBackward>)\n",
      "tensor(2557.1094, grad_fn=<NegBackward>)\n",
      "tensor(18.8543, grad_fn=<NegBackward>)\n",
      "tensor(641.4375, grad_fn=<NegBackward>)\n",
      "tensor(620.8810, grad_fn=<NegBackward>)\n",
      "tensor(2557.1055, grad_fn=<NegBackward>)\n",
      "tensor(18.8699, grad_fn=<NegBackward>)\n",
      "tensor(641.4145, grad_fn=<NegBackward>)\n",
      "tensor(620.7687, grad_fn=<NegBackward>)\n",
      "tensor(2557.1118, grad_fn=<NegBackward>)\n",
      "tensor(18.8850, grad_fn=<NegBackward>)\n",
      "tensor(641.4141, grad_fn=<NegBackward>)\n",
      "tensor(620.6818, grad_fn=<NegBackward>)\n",
      "tensor(2557.1663, grad_fn=<NegBackward>)\n",
      "tensor(18.9051, grad_fn=<NegBackward>)\n",
      "tensor(641.3514, grad_fn=<NegBackward>)\n",
      "tensor(620.6089, grad_fn=<NegBackward>)\n",
      "tensor(2557.2197, grad_fn=<NegBackward>)\n",
      "tensor(18.9258, grad_fn=<NegBackward>)\n",
      "tensor(641.2095, grad_fn=<NegBackward>)\n",
      "tensor(620.5697, grad_fn=<NegBackward>)\n",
      "tensor(2557.2739, grad_fn=<NegBackward>)\n",
      "tensor(18.9488, grad_fn=<NegBackward>)\n",
      "tensor(641.0937, grad_fn=<NegBackward>)\n",
      "tensor(620.5067, grad_fn=<NegBackward>)\n",
      "tensor(2557.3267, grad_fn=<NegBackward>)\n",
      "tensor(18.9699, grad_fn=<NegBackward>)\n",
      "tensor(641.0253, grad_fn=<NegBackward>)\n",
      "tensor(620.4712, grad_fn=<NegBackward>)\n",
      "tensor(2557.4265, grad_fn=<NegBackward>)\n",
      "tensor(18.9877, grad_fn=<NegBackward>)\n",
      "tensor(640.9415, grad_fn=<NegBackward>)\n",
      "tensor(620.4666, grad_fn=<NegBackward>)\n",
      "tensor(2557.5474, grad_fn=<NegBackward>)\n",
      "tensor(19.0110, grad_fn=<NegBackward>)\n",
      "tensor(640.8546, grad_fn=<NegBackward>)\n",
      "tensor(620.4566, grad_fn=<NegBackward>)\n",
      "tensor(2557.6919, grad_fn=<NegBackward>)\n",
      "tensor(19.0364, grad_fn=<NegBackward>)\n",
      "tensor(640.7552, grad_fn=<NegBackward>)\n",
      "tensor(620.4181, grad_fn=<NegBackward>)\n",
      "tensor(2557.8699, grad_fn=<NegBackward>)\n",
      "tensor(19.0576, grad_fn=<NegBackward>)\n",
      "tensor(640.5912, grad_fn=<NegBackward>)\n",
      "tensor(620.3843, grad_fn=<NegBackward>)\n",
      "tensor(2558.1018, grad_fn=<NegBackward>)\n",
      "tensor(19.0797, grad_fn=<NegBackward>)\n",
      "tensor(640.3057, grad_fn=<NegBackward>)\n",
      "tensor(620.3476, grad_fn=<NegBackward>)\n",
      "tensor(2558.3918, grad_fn=<NegBackward>)\n",
      "tensor(19.1065, grad_fn=<NegBackward>)\n",
      "tensor(640.0402, grad_fn=<NegBackward>)\n",
      "tensor(620.3724, grad_fn=<NegBackward>)\n",
      "tensor(2558.6304, grad_fn=<NegBackward>)\n",
      "tensor(19.1296, grad_fn=<NegBackward>)\n",
      "tensor(639.8589, grad_fn=<NegBackward>)\n",
      "tensor(620.4294, grad_fn=<NegBackward>)\n",
      "tensor(2558.9109, grad_fn=<NegBackward>)\n",
      "tensor(19.1550, grad_fn=<NegBackward>)\n",
      "tensor(639.5672, grad_fn=<NegBackward>)\n",
      "tensor(620.4047, grad_fn=<NegBackward>)\n",
      "tensor(2559.1511, grad_fn=<NegBackward>)\n",
      "tensor(19.1796, grad_fn=<NegBackward>)\n",
      "tensor(639.2930, grad_fn=<NegBackward>)\n",
      "tensor(620.4185, grad_fn=<NegBackward>)\n",
      "tensor(2559.4417, grad_fn=<NegBackward>)\n",
      "tensor(19.2071, grad_fn=<NegBackward>)\n",
      "tensor(639.0350, grad_fn=<NegBackward>)\n",
      "tensor(620.3829, grad_fn=<NegBackward>)\n",
      "tensor(2559.6189, grad_fn=<NegBackward>)\n",
      "tensor(19.2317, grad_fn=<NegBackward>)\n",
      "tensor(638.9308, grad_fn=<NegBackward>)\n",
      "tensor(620.3865, grad_fn=<NegBackward>)\n",
      "tensor(2559.7034, grad_fn=<NegBackward>)\n",
      "tensor(19.2580, grad_fn=<NegBackward>)\n",
      "tensor(638.8555, grad_fn=<NegBackward>)\n",
      "tensor(620.4026, grad_fn=<NegBackward>)\n",
      "tensor(2559.8018, grad_fn=<NegBackward>)\n",
      "tensor(19.2846, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = train_cmu_mosi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f07c427-de4e-4f12-8363-39219b3c538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69dc9a15-b8dc-4a77-89e5-747779ea286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shapeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d711c0a-0264-4a31-88af-809fc55e99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b9fa28-d31d-45ae-b5a5-142805902a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = td.Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4cc955b-96f2-4127-8f71-7f2c6bfa44fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1587)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.cdf(torch.tensor(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a05ae421-793a-48da-9567-c87c141a98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = model.tensor_fusion_layer.weight_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5763818c-ed02-466a-8be5-fa03ad663329",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_scale = 1e-9\n",
    "factor_dist = td.Normal(loc=0, scale=tensor.rank_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13c5d47d-1a93-4cb6-bacb-55f8e98a6a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1616,  0.2713, -0.1114,  0.0177,  0.2770,  0.1499, -0.0087,  0.0943,\n",
       "         0.1177, -0.0481,  0.0643,  0.1426, -0.0518, -0.0145,  0.0151,  0.0486,\n",
       "        -0.0546, -0.0239,  0.3509,  0.0476], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.factors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1697a03a-6ebe-4580-a1fd-295627225601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.9501, 0.2737, 0.5453, 0.9428, 0.8083, 0.4792, 0.7029, 0.7608,\n",
       "         0.3821, 0.6439, 0.7983, 0.3786, 0.4666, 0.5341, 0.6188, 0.3771, 0.4454,\n",
       "         0.9798, 0.6127]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dist.cdf(tensor.factors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d57accd-6033-478e-8837-19fe74c297f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.9501, 0.2737, 0.5453, 0.9428, 0.8083, 0.4792, 0.7029, 0.7608,\n",
       "         0.3821, 0.6439, 0.7983, 0.3786, 0.4666, 0.5341, 0.6188, 0.3771, 0.4454,\n",
       "         0.9798, 0.6127],\n",
       "        [0.6176, 0.7911, 0.2937, 0.6401, 0.9798, 0.4173, 0.8173, 0.7636, 0.7208,\n",
       "         0.9178, 0.8128, 0.9612, 0.8145, 0.4543, 0.4445, 0.5084, 0.4040, 0.1602,\n",
       "         0.2736, 0.2127],\n",
       "        [0.8112, 0.4306, 0.7227, 0.6602, 0.8213, 0.0386, 0.6663, 0.5947, 0.1200,\n",
       "         0.3541, 0.3249, 0.9399, 0.2074, 0.6484, 0.4268, 0.1778, 0.4798, 0.7598,\n",
       "         0.0732, 0.3149],\n",
       "        [0.8229, 0.0717, 0.2684, 0.0650, 0.8956, 0.8945, 0.6467, 0.2294, 0.1787,\n",
       "         0.4025, 0.0838, 0.3088, 0.2935, 0.4559, 0.4754, 0.9647, 0.0382, 0.0778,\n",
       "         0.4810, 0.0702],\n",
       "        [0.7859, 0.1282, 0.0739, 0.6209, 0.9866, 0.7137, 0.7140, 0.5657, 0.6711,\n",
       "         0.1053, 0.0805, 0.9103, 0.1144, 0.4349, 0.8268, 0.9001, 0.5141, 0.6955,\n",
       "         0.5202, 0.9097],\n",
       "        [0.1704, 0.8412, 0.0365, 0.0144, 0.4696, 0.7992, 0.4430, 0.5475, 0.6428,\n",
       "         0.2614, 0.0977, 0.3526, 0.6945, 0.2127, 0.1588, 0.1436, 0.3480, 0.0581,\n",
       "         0.7499, 0.4480],\n",
       "        [0.2465, 0.2999, 0.4817, 0.2829, 0.0313, 0.0309, 0.4765, 0.3698, 0.9276,\n",
       "         0.5317, 0.4063, 0.7834, 0.5096, 0.1509, 0.0913, 0.7145, 0.5848, 0.8319,\n",
       "         0.5640, 0.0190],\n",
       "        [0.5136, 0.6315, 0.0980, 0.2360, 0.1646, 0.6339, 0.0975, 0.5749, 0.5213,\n",
       "         0.2589, 0.4584, 0.4774, 0.4584, 0.7363, 0.1203, 0.2423, 0.6256, 0.0228,\n",
       "         0.1681, 0.1987],\n",
       "        [0.9414, 0.3346, 0.3224, 0.8057, 0.9710, 0.1439, 0.8598, 0.2619, 0.2043,\n",
       "         0.1131, 0.9777, 0.9964, 0.6542, 0.5063, 0.2582, 0.6619, 0.6898, 0.5259,\n",
       "         0.8709, 0.4013],\n",
       "        [0.7066, 0.8901, 0.0987, 0.0095, 0.5114, 0.6962, 0.2917, 0.7791, 0.5660,\n",
       "         0.2865, 0.9844, 0.4065, 0.1264, 0.3623, 0.0677, 0.1381, 0.7598, 0.6922,\n",
       "         0.2963, 0.7718],\n",
       "        [0.1948, 0.7798, 0.0111, 0.0444, 0.0971, 0.3081, 0.8402, 0.5876, 0.4418,\n",
       "         0.4060, 0.1596, 0.5350, 0.8867, 0.4106, 0.4082, 0.9088, 0.9565, 0.7367,\n",
       "         0.5300, 0.5308],\n",
       "        [0.0032, 0.1637, 0.5410, 0.0792, 0.9671, 0.8886, 0.0591, 0.6869, 0.7396,\n",
       "         0.0136, 0.3419, 0.3987, 0.4197, 0.3771, 0.5648, 0.9257, 0.3185, 0.5582,\n",
       "         0.4857, 0.9737],\n",
       "        [0.0297, 0.6184, 0.8506, 0.3079, 0.3990, 0.9701, 0.6904, 0.1155, 0.6031,\n",
       "         0.6535, 0.5421, 0.0498, 0.8137, 0.4376, 0.8045, 0.8571, 0.1532, 0.0706,\n",
       "         0.4977, 0.3350],\n",
       "        [0.1223, 0.9063, 0.6186, 0.0447, 0.2841, 0.2755, 0.5466, 0.0325, 0.3027,\n",
       "         0.1012, 0.9586, 0.2705, 0.0379, 0.2653, 0.3897, 0.2853, 0.1411, 0.0890,\n",
       "         0.9036, 0.3202],\n",
       "        [0.6777, 0.2988, 0.6557, 0.4447, 0.3960, 0.8022, 0.8621, 0.7278, 0.7952,\n",
       "         0.9550, 0.2626, 0.4038, 0.5955, 0.5128, 0.0121, 0.9246, 0.0155, 0.2435,\n",
       "         0.1283, 0.0468],\n",
       "        [0.3469, 0.9706, 0.3441, 0.7236, 0.0067, 0.3257, 0.6852, 0.8911, 0.5976,\n",
       "         0.0803, 0.8260, 0.8053, 0.2903, 0.9522, 0.0362, 0.9042, 0.9096, 0.0754,\n",
       "         0.6900, 0.8779],\n",
       "        [0.1341, 0.1583, 0.0184, 0.2661, 0.3175, 0.9315, 0.3427, 0.4894, 0.2338,\n",
       "         0.1034, 0.2477, 0.6325, 0.9589, 0.3074, 0.5141, 0.9432, 0.6343, 0.5238,\n",
       "         0.4140, 0.8284],\n",
       "        [0.5080, 0.4115, 0.0984, 0.8044, 0.0452, 0.8535, 0.9760, 0.8316, 0.5514,\n",
       "         0.6858, 0.6767, 0.1074, 0.2641, 0.2297, 0.7935, 0.9153, 0.6038, 0.1350,\n",
       "         0.5370, 0.7321],\n",
       "        [0.8441, 0.7141, 0.6206, 0.3693, 0.4586, 0.8482, 0.4607, 0.9647, 0.0132,\n",
       "         0.6633, 0.7438, 0.5810, 0.3060, 0.1604, 0.4570, 0.6424, 0.2249, 0.9139,\n",
       "         0.7233, 0.2998],\n",
       "        [0.5429, 0.0334, 0.1316, 0.0187, 0.4332, 0.6209, 0.9843, 0.4885, 0.3517,\n",
       "         0.1146, 0.1831, 0.7397, 0.1707, 0.9783, 0.2454, 0.9204, 0.0037, 0.5828,\n",
       "         0.1630, 0.2177],\n",
       "        [0.4349, 0.2984, 0.0819, 0.1373, 0.4821, 0.3676, 0.2707, 0.7487, 0.8878,\n",
       "         0.5715, 0.6932, 0.9200, 0.9497, 0.1125, 0.1152, 0.5965, 0.3879, 0.4958,\n",
       "         0.4454, 0.7559],\n",
       "        [0.9330, 0.1424, 0.9010, 0.0399, 0.7024, 0.5782, 0.3511, 0.7893, 0.8032,\n",
       "         0.7845, 0.1424, 0.4149, 0.4327, 0.6834, 0.9302, 0.4815, 0.4256, 0.8264,\n",
       "         0.4124, 0.1497],\n",
       "        [0.0596, 0.0809, 0.2099, 0.6430, 0.7111, 0.1021, 0.3891, 0.0035, 0.0594,\n",
       "         0.5044, 0.6854, 0.2628, 0.8587, 0.6074, 0.1939, 0.1525, 0.4609, 0.8000,\n",
       "         0.3116, 0.3939],\n",
       "        [0.5468, 0.9835, 0.4166, 0.8787, 0.5833, 0.9368, 0.7450, 0.8959, 0.6294,\n",
       "         0.3074, 0.8222, 0.3951, 0.4229, 0.4755, 0.8152, 0.3646, 0.4657, 0.3016,\n",
       "         0.9853, 0.9721],\n",
       "        [0.2137, 0.1262, 0.0719, 0.8968, 0.7876, 0.5476, 0.6462, 0.2857, 0.1099,\n",
       "         0.8856, 0.7664, 0.9471, 0.0101, 0.7863, 0.5935, 0.4257, 0.7040, 0.5782,\n",
       "         0.1076, 0.2028],\n",
       "        [0.3614, 0.5125, 0.7419, 0.2159, 0.9907, 0.4285, 0.9120, 0.8319, 0.0742,\n",
       "         0.6428, 0.9527, 0.2003, 0.9574, 0.4863, 0.2947, 0.1820, 0.0872, 0.2532,\n",
       "         0.4479, 0.3796],\n",
       "        [0.0641, 0.2652, 0.0728, 0.1638, 0.2267, 0.0952, 0.5943, 0.5566, 0.9188,\n",
       "         0.4793, 0.2608, 0.9943, 0.0962, 0.6424, 0.5931, 0.0470, 0.0917, 0.0731,\n",
       "         0.3294, 0.1094],\n",
       "        [0.1727, 0.0869, 0.0722, 0.8499, 0.0586, 0.4110, 0.1599, 0.0595, 0.2706,\n",
       "         0.7429, 0.4268, 0.1743, 0.0196, 0.1912, 0.3848, 0.0805, 0.6907, 0.7416,\n",
       "         0.3368, 0.9379],\n",
       "        [0.2563, 0.7708, 0.8251, 0.1995, 0.2419, 0.4604, 0.2644, 0.5493, 0.8263,\n",
       "         0.7945, 0.1662, 0.0924, 0.8419, 0.1521, 0.6419, 0.3839, 0.7832, 0.7331,\n",
       "         0.5911, 0.9753],\n",
       "        [0.4920, 0.0546, 0.6955, 0.3491, 0.5942, 0.7411, 0.4740, 0.3758, 0.5125,\n",
       "         0.9117, 0.6287, 0.5718, 0.5805, 0.0079, 0.8093, 0.7544, 0.5879, 0.4059,\n",
       "         0.4722, 0.4305],\n",
       "        [0.3223, 0.0454, 0.6318, 0.3005, 0.5050, 0.8016, 0.3929, 0.7795, 0.8103,\n",
       "         0.9606, 0.6995, 0.0492, 0.1551, 0.2352, 0.0738, 0.9582, 0.9144, 0.7190,\n",
       "         0.4381, 0.6792],\n",
       "        [0.4981, 0.0496, 0.3679, 0.8002, 0.6942, 0.8196, 0.4658, 0.3293, 0.8755,\n",
       "         0.2223, 0.8951, 0.1149, 0.9064, 0.3799, 0.5136, 0.8223, 0.0926, 0.2455,\n",
       "         0.7212, 0.7911],\n",
       "        [0.1636, 0.3940, 0.2821, 0.4362, 0.3406, 0.4511, 0.3392, 0.1590, 0.7907,\n",
       "         0.0079, 0.4882, 0.0716, 0.8389, 0.9336, 0.0223, 0.9902, 0.2415, 0.0743,\n",
       "         0.0883, 0.8706]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dist.cdf(tensor.factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de99a170-671c-490c-ba9c-6dc7d8d5dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1653, 0.1648, 0.1852, 0.1560, 0.1755, 0.1720, 0.1666, 0.1770, 0.1661,\n",
      "         0.1602, 0.1742, 0.1707, 0.1674, 0.1738, 0.1759, 0.1608, 0.1744, 0.1742,\n",
      "         0.1711, 0.1663]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.rank_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac16ec-f17e-4cb6-a56d-e1b12096c5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
