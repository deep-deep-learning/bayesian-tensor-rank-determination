{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc5f4897-7608-414a-8887-ab5ad2bbaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datasets import Multimodal_Binary_Dataset, MultimodalDataset\n",
    "from fusion_model import CP_Tensor_Fusion_Network\n",
    "from model import TFN\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d2c45b9-5fd9-48b5-b441-cab6251d961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cmu_mosi(batch_size=32, epochs=100, lr=.001, max_rank=5, rank_adaptive=False,  \n",
    "                   warmup_epochs=50, kl_multiplier=1e-4, no_kl_epochs=5, accelerated=True):\n",
    "\n",
    "    # load dataset file\n",
    "    file = open('../../dataset/cmu-mosi/mosi_20_seq_data.pkl', 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # prepare the datasets and data loaders\n",
    "    train_set = MultimodalDataset(data['train']['text'], data['train']['audio'],\n",
    "                                  data['train']['vision'], data['train']['labels'])\n",
    "    valid_set = MultimodalDataset(data['valid']['text'], data['valid']['audio'],\n",
    "                                  data['valid']['vision'], data['valid']['labels'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "\n",
    "    # set up model\n",
    "    input_sizes = (train_set[0][0]['audio'].shape[0], train_set[0][0]['vision'].shape[0],\n",
    "                   train_set[0][0]['text'].shape[1])\n",
    "    hidden_sizes = (32, 32, 128)\n",
    "    output_size = 1\n",
    "    \n",
    "    # model = CP_Tensor_Fusion_Network(input_sizes, hidden_sizes, output_size, max_rank,\n",
    "    #                                  rank_adaptive)\n",
    "    \n",
    "    model = TFN(input_dims=input_sizes, hidden_dims=hidden_sizes, text_out=128, dropouts=(0.3, 0.3, 0.3, 0.3), \n",
    "                post_fusion_dim=1)\n",
    "    \n",
    "    # set up training\n",
    "    DTYPE = torch.FloatTensor\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    \n",
    "    # train and validate\n",
    "    for e in range(1, epochs + 1):\n",
    "        # train\n",
    "        tic = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            features, label = batch\n",
    "            \n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            \n",
    "            output = model(x_a, x_v, x_t)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        print('Train Loss {:.3f}'.format(train_loss))\n",
    "        '''\n",
    "        print(model.audio_subnet.linear_2.weight.grad.mean())\n",
    "        print(model.video_subnet.linear_2.weight.grad.mean())\n",
    "        print(model.text_subnet.linear_1.weight.grad.mean())\n",
    "        print(model.tensor_fusion_layer.weight_tensor.factors[0].grad.mean())\n",
    "        '''\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        for batch in valid_dataloader:\n",
    "            features, label = batch\n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "\n",
    "            output = model(x_a, x_v, x_t)\n",
    "        \n",
    "        valid_mse = nn.functional.mse_loss(output, y).item()\n",
    "        print(\"Valid MSE {:.3f}\".format(valid_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b21b4-63e2-4d99-9dc6-485a33647532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 92.932\n",
      "Valid MSE 2.567\n"
     ]
    }
   ],
   "source": [
    "train_cmu_mosi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e46410be-e759-4244-b5d5-184a91a68a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f07c427-de4e-4f12-8363-39219b3c538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf6b4a4-5d2a-4c06-a872-9151e3405a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import halfcauchy, loguniform, norm, truncnorm\n",
    "import numpy as np\n",
    "\n",
    "from torch.distributions.half_cauchy import HalfCauchy\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41096bf-9b8b-4d21-9f91-f21f0f3affc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptive_CP_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, output_size, max_rank):\n",
    "        \n",
    "        super(Adaptive_CP_Linear, self).__init__()\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        shape = input_sizes + (output_size,)\n",
    "        self.weight = CP(shape, max_rank)\n",
    "        \n",
    "    def forard(self, inputs):\n",
    "        y = 1.0\n",
    "        for i, x in enumerate(inputs):\n",
    "            y = y * (x @ self.weight_tensor_factors[i])\n",
    "        y = y @ self.weight_tensor_factors[-1].T\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f32e082-db5a-4562-9350-95402df12fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape, max_rank, prior_type='log_uniform', eta=None):\n",
    "        \n",
    "        super(CP, self).__init__()\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.order = len(shape)\n",
    "        self.max_rank = max_rank\n",
    "        self.prior_type = prior_type\n",
    "        \n",
    "        self.factors = nn.ParameterList([nn.init.xavier_normal_(nn.Parameter(torch.empty(s, max_rank)))\n",
    "                                         for s in shape])\n",
    "        \n",
    "        self.rank_params = nn.Parameter(torch.rand(max_rank))\n",
    "        \n",
    "    def log_priors(self):\n",
    "        \n",
    "        log_priors = 0.0\n",
    "        \n",
    "        rank_params_dist = HalfCauchy(1.0)\n",
    "        log_priors += rank_params_dist.log_prob(self.rank_params).sum()\n",
    "        \n",
    "        factors_dist = Normal(0, self.rank_params)\n",
    "        for f in self.factors:\n",
    "            log_priors += factors_dist.log_prob(f).sum()\n",
    "        \n",
    "        return log_priors\n",
    "    '''\n",
    "    def init_factors(self):\n",
    "        \n",
    "        target_stddev = np.sqrt(2/np.prod(self.shape[:-1]))\n",
    "        factor_stddev = np.power(target_stddev / self.max_rank, 1 / self.order)\n",
    "        init_dist = truncnorm(a=-3.0*factor_stddev, b=3.0*factor_stddev, \n",
    "                              loc=0.0, scale=factor_stddev)\n",
    "        for s in self.shape:\n",
    "            self.factors.append(nn.Parameter(torch.tensor(init_dist.rvs((s, self.max_rank)), \n",
    "                                                          dtype=torch.float32)))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69dca1e-d5af-49a5-9a47-db757be7aaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69dc9a15-b8dc-4a77-89e5-747779ea286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shapeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d711c0a-0264-4a31-88af-809fc55e99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b9fa28-d31d-45ae-b5a5-142805902a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = td.Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4cc955b-96f2-4127-8f71-7f2c6bfa44fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1587)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.cdf(torch.tensor(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a05ae421-793a-48da-9567-c87c141a98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = model.tensor_fusion_layer.weight_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5763818c-ed02-466a-8be5-fa03ad663329",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_scale = 1e-9\n",
    "factor_dist = td.Normal(loc=0, scale=tensor.rank_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13c5d47d-1a93-4cb6-bacb-55f8e98a6a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1616,  0.2713, -0.1114,  0.0177,  0.2770,  0.1499, -0.0087,  0.0943,\n",
       "         0.1177, -0.0481,  0.0643,  0.1426, -0.0518, -0.0145,  0.0151,  0.0486,\n",
       "        -0.0546, -0.0239,  0.3509,  0.0476], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.factors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1697a03a-6ebe-4580-a1fd-295627225601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.9501, 0.2737, 0.5453, 0.9428, 0.8083, 0.4792, 0.7029, 0.7608,\n",
       "         0.3821, 0.6439, 0.7983, 0.3786, 0.4666, 0.5341, 0.6188, 0.3771, 0.4454,\n",
       "         0.9798, 0.6127]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dist.cdf(tensor.factors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d57accd-6033-478e-8837-19fe74c297f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.9501, 0.2737, 0.5453, 0.9428, 0.8083, 0.4792, 0.7029, 0.7608,\n",
       "         0.3821, 0.6439, 0.7983, 0.3786, 0.4666, 0.5341, 0.6188, 0.3771, 0.4454,\n",
       "         0.9798, 0.6127],\n",
       "        [0.6176, 0.7911, 0.2937, 0.6401, 0.9798, 0.4173, 0.8173, 0.7636, 0.7208,\n",
       "         0.9178, 0.8128, 0.9612, 0.8145, 0.4543, 0.4445, 0.5084, 0.4040, 0.1602,\n",
       "         0.2736, 0.2127],\n",
       "        [0.8112, 0.4306, 0.7227, 0.6602, 0.8213, 0.0386, 0.6663, 0.5947, 0.1200,\n",
       "         0.3541, 0.3249, 0.9399, 0.2074, 0.6484, 0.4268, 0.1778, 0.4798, 0.7598,\n",
       "         0.0732, 0.3149],\n",
       "        [0.8229, 0.0717, 0.2684, 0.0650, 0.8956, 0.8945, 0.6467, 0.2294, 0.1787,\n",
       "         0.4025, 0.0838, 0.3088, 0.2935, 0.4559, 0.4754, 0.9647, 0.0382, 0.0778,\n",
       "         0.4810, 0.0702],\n",
       "        [0.7859, 0.1282, 0.0739, 0.6209, 0.9866, 0.7137, 0.7140, 0.5657, 0.6711,\n",
       "         0.1053, 0.0805, 0.9103, 0.1144, 0.4349, 0.8268, 0.9001, 0.5141, 0.6955,\n",
       "         0.5202, 0.9097],\n",
       "        [0.1704, 0.8412, 0.0365, 0.0144, 0.4696, 0.7992, 0.4430, 0.5475, 0.6428,\n",
       "         0.2614, 0.0977, 0.3526, 0.6945, 0.2127, 0.1588, 0.1436, 0.3480, 0.0581,\n",
       "         0.7499, 0.4480],\n",
       "        [0.2465, 0.2999, 0.4817, 0.2829, 0.0313, 0.0309, 0.4765, 0.3698, 0.9276,\n",
       "         0.5317, 0.4063, 0.7834, 0.5096, 0.1509, 0.0913, 0.7145, 0.5848, 0.8319,\n",
       "         0.5640, 0.0190],\n",
       "        [0.5136, 0.6315, 0.0980, 0.2360, 0.1646, 0.6339, 0.0975, 0.5749, 0.5213,\n",
       "         0.2589, 0.4584, 0.4774, 0.4584, 0.7363, 0.1203, 0.2423, 0.6256, 0.0228,\n",
       "         0.1681, 0.1987],\n",
       "        [0.9414, 0.3346, 0.3224, 0.8057, 0.9710, 0.1439, 0.8598, 0.2619, 0.2043,\n",
       "         0.1131, 0.9777, 0.9964, 0.6542, 0.5063, 0.2582, 0.6619, 0.6898, 0.5259,\n",
       "         0.8709, 0.4013],\n",
       "        [0.7066, 0.8901, 0.0987, 0.0095, 0.5114, 0.6962, 0.2917, 0.7791, 0.5660,\n",
       "         0.2865, 0.9844, 0.4065, 0.1264, 0.3623, 0.0677, 0.1381, 0.7598, 0.6922,\n",
       "         0.2963, 0.7718],\n",
       "        [0.1948, 0.7798, 0.0111, 0.0444, 0.0971, 0.3081, 0.8402, 0.5876, 0.4418,\n",
       "         0.4060, 0.1596, 0.5350, 0.8867, 0.4106, 0.4082, 0.9088, 0.9565, 0.7367,\n",
       "         0.5300, 0.5308],\n",
       "        [0.0032, 0.1637, 0.5410, 0.0792, 0.9671, 0.8886, 0.0591, 0.6869, 0.7396,\n",
       "         0.0136, 0.3419, 0.3987, 0.4197, 0.3771, 0.5648, 0.9257, 0.3185, 0.5582,\n",
       "         0.4857, 0.9737],\n",
       "        [0.0297, 0.6184, 0.8506, 0.3079, 0.3990, 0.9701, 0.6904, 0.1155, 0.6031,\n",
       "         0.6535, 0.5421, 0.0498, 0.8137, 0.4376, 0.8045, 0.8571, 0.1532, 0.0706,\n",
       "         0.4977, 0.3350],\n",
       "        [0.1223, 0.9063, 0.6186, 0.0447, 0.2841, 0.2755, 0.5466, 0.0325, 0.3027,\n",
       "         0.1012, 0.9586, 0.2705, 0.0379, 0.2653, 0.3897, 0.2853, 0.1411, 0.0890,\n",
       "         0.9036, 0.3202],\n",
       "        [0.6777, 0.2988, 0.6557, 0.4447, 0.3960, 0.8022, 0.8621, 0.7278, 0.7952,\n",
       "         0.9550, 0.2626, 0.4038, 0.5955, 0.5128, 0.0121, 0.9246, 0.0155, 0.2435,\n",
       "         0.1283, 0.0468],\n",
       "        [0.3469, 0.9706, 0.3441, 0.7236, 0.0067, 0.3257, 0.6852, 0.8911, 0.5976,\n",
       "         0.0803, 0.8260, 0.8053, 0.2903, 0.9522, 0.0362, 0.9042, 0.9096, 0.0754,\n",
       "         0.6900, 0.8779],\n",
       "        [0.1341, 0.1583, 0.0184, 0.2661, 0.3175, 0.9315, 0.3427, 0.4894, 0.2338,\n",
       "         0.1034, 0.2477, 0.6325, 0.9589, 0.3074, 0.5141, 0.9432, 0.6343, 0.5238,\n",
       "         0.4140, 0.8284],\n",
       "        [0.5080, 0.4115, 0.0984, 0.8044, 0.0452, 0.8535, 0.9760, 0.8316, 0.5514,\n",
       "         0.6858, 0.6767, 0.1074, 0.2641, 0.2297, 0.7935, 0.9153, 0.6038, 0.1350,\n",
       "         0.5370, 0.7321],\n",
       "        [0.8441, 0.7141, 0.6206, 0.3693, 0.4586, 0.8482, 0.4607, 0.9647, 0.0132,\n",
       "         0.6633, 0.7438, 0.5810, 0.3060, 0.1604, 0.4570, 0.6424, 0.2249, 0.9139,\n",
       "         0.7233, 0.2998],\n",
       "        [0.5429, 0.0334, 0.1316, 0.0187, 0.4332, 0.6209, 0.9843, 0.4885, 0.3517,\n",
       "         0.1146, 0.1831, 0.7397, 0.1707, 0.9783, 0.2454, 0.9204, 0.0037, 0.5828,\n",
       "         0.1630, 0.2177],\n",
       "        [0.4349, 0.2984, 0.0819, 0.1373, 0.4821, 0.3676, 0.2707, 0.7487, 0.8878,\n",
       "         0.5715, 0.6932, 0.9200, 0.9497, 0.1125, 0.1152, 0.5965, 0.3879, 0.4958,\n",
       "         0.4454, 0.7559],\n",
       "        [0.9330, 0.1424, 0.9010, 0.0399, 0.7024, 0.5782, 0.3511, 0.7893, 0.8032,\n",
       "         0.7845, 0.1424, 0.4149, 0.4327, 0.6834, 0.9302, 0.4815, 0.4256, 0.8264,\n",
       "         0.4124, 0.1497],\n",
       "        [0.0596, 0.0809, 0.2099, 0.6430, 0.7111, 0.1021, 0.3891, 0.0035, 0.0594,\n",
       "         0.5044, 0.6854, 0.2628, 0.8587, 0.6074, 0.1939, 0.1525, 0.4609, 0.8000,\n",
       "         0.3116, 0.3939],\n",
       "        [0.5468, 0.9835, 0.4166, 0.8787, 0.5833, 0.9368, 0.7450, 0.8959, 0.6294,\n",
       "         0.3074, 0.8222, 0.3951, 0.4229, 0.4755, 0.8152, 0.3646, 0.4657, 0.3016,\n",
       "         0.9853, 0.9721],\n",
       "        [0.2137, 0.1262, 0.0719, 0.8968, 0.7876, 0.5476, 0.6462, 0.2857, 0.1099,\n",
       "         0.8856, 0.7664, 0.9471, 0.0101, 0.7863, 0.5935, 0.4257, 0.7040, 0.5782,\n",
       "         0.1076, 0.2028],\n",
       "        [0.3614, 0.5125, 0.7419, 0.2159, 0.9907, 0.4285, 0.9120, 0.8319, 0.0742,\n",
       "         0.6428, 0.9527, 0.2003, 0.9574, 0.4863, 0.2947, 0.1820, 0.0872, 0.2532,\n",
       "         0.4479, 0.3796],\n",
       "        [0.0641, 0.2652, 0.0728, 0.1638, 0.2267, 0.0952, 0.5943, 0.5566, 0.9188,\n",
       "         0.4793, 0.2608, 0.9943, 0.0962, 0.6424, 0.5931, 0.0470, 0.0917, 0.0731,\n",
       "         0.3294, 0.1094],\n",
       "        [0.1727, 0.0869, 0.0722, 0.8499, 0.0586, 0.4110, 0.1599, 0.0595, 0.2706,\n",
       "         0.7429, 0.4268, 0.1743, 0.0196, 0.1912, 0.3848, 0.0805, 0.6907, 0.7416,\n",
       "         0.3368, 0.9379],\n",
       "        [0.2563, 0.7708, 0.8251, 0.1995, 0.2419, 0.4604, 0.2644, 0.5493, 0.8263,\n",
       "         0.7945, 0.1662, 0.0924, 0.8419, 0.1521, 0.6419, 0.3839, 0.7832, 0.7331,\n",
       "         0.5911, 0.9753],\n",
       "        [0.4920, 0.0546, 0.6955, 0.3491, 0.5942, 0.7411, 0.4740, 0.3758, 0.5125,\n",
       "         0.9117, 0.6287, 0.5718, 0.5805, 0.0079, 0.8093, 0.7544, 0.5879, 0.4059,\n",
       "         0.4722, 0.4305],\n",
       "        [0.3223, 0.0454, 0.6318, 0.3005, 0.5050, 0.8016, 0.3929, 0.7795, 0.8103,\n",
       "         0.9606, 0.6995, 0.0492, 0.1551, 0.2352, 0.0738, 0.9582, 0.9144, 0.7190,\n",
       "         0.4381, 0.6792],\n",
       "        [0.4981, 0.0496, 0.3679, 0.8002, 0.6942, 0.8196, 0.4658, 0.3293, 0.8755,\n",
       "         0.2223, 0.8951, 0.1149, 0.9064, 0.3799, 0.5136, 0.8223, 0.0926, 0.2455,\n",
       "         0.7212, 0.7911],\n",
       "        [0.1636, 0.3940, 0.2821, 0.4362, 0.3406, 0.4511, 0.3392, 0.1590, 0.7907,\n",
       "         0.0079, 0.4882, 0.0716, 0.8389, 0.9336, 0.0223, 0.9902, 0.2415, 0.0743,\n",
       "         0.0883, 0.8706]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dist.cdf(tensor.factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de99a170-671c-490c-ba9c-6dc7d8d5dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1653, 0.1648, 0.1852, 0.1560, 0.1755, 0.1720, 0.1666, 0.1770, 0.1661,\n",
      "         0.1602, 0.1742, 0.1707, 0.1674, 0.1738, 0.1759, 0.1608, 0.1744, 0.1742,\n",
      "         0.1711, 0.1663]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.rank_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac16ec-f17e-4cb6-a56d-e1b12096c5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
