{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322e43c3-e47a-44f9-9f88-9f24f3fcee4c",
   "metadata": {},
   "source": [
    "Negative log likelihood loss\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/negative-log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df0828-9a6b-4568-9602-dc772134c5bf",
   "metadata": {},
   "source": [
    "Trying to implement the negative log loss for the priors\n",
    "\n",
    "$p(\\theta)=p(\\lambda)\\prod_n p(U^{(n)}|\\lambda)$\\\n",
    "$\\ \\ \\ \\ \\ \\ \\ =\\prod_j p(\\lambda_j) \\prod_n \\prod_{i,j} \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j)$\n",
    "\n",
    "$\\ \\ \\ -\\log p(\\theta)$\\\n",
    "$= -\\log \\left( \\prod_j p(\\lambda_j) \\prod_n \\prod_{i,j} \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j) \\right)$\\\n",
    "$= -\\left( \\sum_j \\log p(\\lambda_j) + \\sum_n \\sum_{i,j} \\log \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412f1f20-3717-4283-9abc-931306018151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import halfcauchy, loguniform, norm, truncnorm\n",
    "import numpy as np\n",
    "\n",
    "from torch.distributions.half_cauchy import HalfCauchy\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datasets import Multimodal_Binary_Dataset\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from model import SubNet, TextSubNet\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb5dbe-2bbf-4c9d-b5d6-25e310fee7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptive_CP_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, output_size, max_rank):\n",
    "        \n",
    "        super(Adaptive_CP_Linear, self).__init__()\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        shape = input_sizes + (output_size,)\n",
    "        self.weight = CP(shape, max_rank)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        y = 1.0\n",
    "        for i, x in enumerate(inputs):\n",
    "            y = y * (x @ self.weight.factors[i])\n",
    "        y = y @ self.weight.factors[-1].T\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b30da4f6-b74d-4c6d-bbf0-df4db49e9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape, max_rank, prior_type='log_uniform', eta=None):\n",
    "        \n",
    "        super(CP, self).__init__()\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.order = len(shape)\n",
    "        self.max_rank = max_rank\n",
    "        self.prior_type = prior_type\n",
    "        \n",
    "        self.factors = nn.ParameterList([nn.init.xavier_normal_(nn.Parameter(torch.empty(s, max_rank)))\n",
    "                                         for s in shape])\n",
    "        \n",
    "        self.rank_params = nn.Parameter(torch.rand(max_rank))\n",
    "        \n",
    "    def log_priors(self):\n",
    "        \n",
    "        log_priors = 0.0\n",
    "        \n",
    "        rank_params_dist = HalfCauchy(1.0)\n",
    "        self.rank_params = nn.Parameter(nn.functional.relu(self.rank_params))\n",
    "        try:\n",
    "            log_priors += rank_params_dist.log_prob(self.rank_params).sum()\n",
    "        except ValueError:\n",
    "            print(self.rank_params)\n",
    "            \n",
    "        factors_dist = Normal(0, self.rank_params)\n",
    "        for f in self.factors:\n",
    "            try:\n",
    "                log_priors += factors_dist.log_prob(f).sum()\n",
    "            except ValueError:\n",
    "                print(f)\n",
    "        return log_priors\n",
    "    '''\n",
    "    def init_factors(self):\n",
    "        \n",
    "        target_stddev = np.sqrt(2/np.prod(self.shape[:-1]))\n",
    "        factor_stddev = np.power(target_stddev / self.max_rank, 1 / self.order)\n",
    "        init_dist = truncnorm(a=-3.0*factor_stddev, b=3.0*factor_stddev, \n",
    "                              loc=0.0, scale=factor_stddev)\n",
    "        for s in self.shape:\n",
    "            self.factors.append(nn.Parameter(torch.tensor(init_dist.rvs((s, self.max_rank)), \n",
    "                                                          dtype=torch.float32)))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17ccbab5-d3c7-49e9-bf58-914b6ccc170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cmu_mosi(batch_size=32, epochs=100, lr=.001, max_rank=20):\n",
    "\n",
    "    # load dataset file\n",
    "    file = open('../../dataset/cmu-mosi/mosi_20_seq_data.pkl', 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # prepare the datasets and data loaders\n",
    "    train_set = Multimodal_Binary_Dataset(data['train']['text'], data['train']['audio'],\n",
    "                                  data['train']['vision'], data['train']['labels'])\n",
    "    valid_set = Multimodal_Binary_Dataset(data['valid']['text'], data['valid']['audio'],\n",
    "                                  data['valid']['vision'], data['valid']['labels'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "\n",
    "    # set up model\n",
    "    input_sizes = (train_set[0][0]['audio'].shape[0], train_set[0][0]['vision'].shape[0],\n",
    "                   train_set[0][0]['text'].shape[1])\n",
    "    hidden_sizes = (32, 32, 128)\n",
    "    output_size = 1\n",
    "    \n",
    "    model = CP_Tensor_Fusion_Network(input_sizes, hidden_sizes, output_size, max_rank)\n",
    "    \n",
    "    # set up training\n",
    "    DTYPE = torch.FloatTensor\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # train and validate\n",
    "    for e in range(1, epochs + 1):\n",
    "        # train\n",
    "        tic = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_log_prior = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            features, label = batch\n",
    "            \n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            \n",
    "            output = model([x_a, x_v, x_t])\n",
    "            nll = criterion(output, y)\n",
    "            '''\n",
    "            if e > 50:\n",
    "                log_prior = model.tensor_fusion_layer.weight.log_priors()\n",
    "                loss = nll - 1e-5 * log_prior\n",
    "                \n",
    "                # train_log_prior += log_prior.item()\n",
    "            else:\n",
    "                loss = nll\n",
    "            '''\n",
    "            loss = nll\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        print('Train Loss: {:.4f}'.format(train_loss))\n",
    "        # print('Train Log Prior: {:.4f}'.format(train_log_prior))\n",
    "    \n",
    "        # validate\n",
    "        model.eval()\n",
    "        for batch in valid_dataloader:\n",
    "            features, label = batch\n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "\n",
    "            output = model([x_a, x_v, x_t])\n",
    "\n",
    "        valid_mse = nn.functional.binary_cross_entropy_with_logits(y, output).item()\n",
    "        print(\"Valid MSE {:.3f}\".format(valid_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38c0ad0f-33de-427f-8c47-fd9509d822ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_Tensor_Fusion_Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_sizes, hidden_sizes, output_size, max_rank):\n",
    "\n",
    "        super(CP_Tensor_Fusion_Network, self).__init__()\n",
    "\n",
    "        self.input_sizes = input_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.max_rank = max_rank\n",
    "        \n",
    "        self.audio_subnet = SubNet(input_sizes[0], hidden_sizes[0], dropout=0.3)\n",
    "        self.video_subnet = SubNet(input_sizes[1], hidden_sizes[1], dropout=0.3)\n",
    "        self.text_subnet = TextSubNet(input_sizes[2], hidden_sizes[2], hidden_sizes[2], dropout=0.3)\n",
    "        \n",
    "        tensor_input_sizes = (hidden_sizes[0] + 1, hidden_sizes[1] + 1, hidden_sizes[2] + 1)\n",
    "        self.tensor_fusion_layer = Adaptive_CP_Linear(tensor_input_sizes, output_size, max_rank)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # subnet outputs\n",
    "        z_audio = self.audio_subnet(inputs[0])\n",
    "        z_video = self.video_subnet(inputs[1])\n",
    "        z_text = self.text_subnet(inputs[2])\n",
    "\n",
    "        batch_size = z_audio.data.shape[0]\n",
    "\n",
    "        if z_audio.is_cuda:\n",
    "            DTYPE = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            DTYPE = torch.FloatTensor\n",
    "\n",
    "        # 1 in concatenated to each subnet outputs\n",
    "        z_audio = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_audio), dim=1)\n",
    "        z_video = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_video), dim=1)\n",
    "        z_text = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_text), dim=1)\n",
    "\n",
    "        output = self.tensor_fusion_layer([z_audio, z_video, z_text])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c58e1cd-ec13-4187-b395-86690b656fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 27.3724\n",
      "Valid MSE 0.467\n",
      "Train Loss: 22.4535\n",
      "Valid MSE -0.614\n",
      "Train Loss: 23.2774\n",
      "Valid MSE 0.527\n",
      "Train Loss: 19.3084\n",
      "Valid MSE 0.266\n",
      "Train Loss: 16.5892\n",
      "Valid MSE 0.187\n",
      "Train Loss: 14.3519\n",
      "Valid MSE 0.236\n",
      "Train Loss: 12.8767\n",
      "Valid MSE -0.101\n",
      "Train Loss: 9.7427\n",
      "Valid MSE -0.534\n",
      "Train Loss: 7.9125\n",
      "Valid MSE -0.184\n",
      "Train Loss: 8.7193\n",
      "Valid MSE -2.026\n",
      "Train Loss: 5.9413\n",
      "Valid MSE -1.428\n",
      "Train Loss: 4.5535\n",
      "Valid MSE -1.079\n",
      "Train Loss: 4.5200\n",
      "Valid MSE -2.291\n",
      "Train Loss: 7.5126\n",
      "Valid MSE -1.829\n",
      "Train Loss: 2.9138\n",
      "Valid MSE -3.196\n",
      "Train Loss: 2.1087\n",
      "Valid MSE -2.633\n",
      "Train Loss: 2.2143\n",
      "Valid MSE -4.069\n",
      "Train Loss: 6.9933\n",
      "Valid MSE -0.731\n",
      "Train Loss: 2.6148\n",
      "Valid MSE -2.212\n",
      "Train Loss: 1.4621\n",
      "Valid MSE -2.059\n",
      "Train Loss: 1.1178\n",
      "Valid MSE -2.771\n",
      "Train Loss: 0.5928\n",
      "Valid MSE -4.154\n",
      "Train Loss: 0.9167\n",
      "Valid MSE -3.427\n",
      "Train Loss: 0.4984\n",
      "Valid MSE -3.373\n",
      "Train Loss: 0.4403\n",
      "Valid MSE -4.142\n",
      "Train Loss: 1.0762\n",
      "Valid MSE -3.803\n",
      "Train Loss: 1.2571\n",
      "Valid MSE -3.565\n",
      "Train Loss: 0.7272\n",
      "Valid MSE -3.736\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a99603692e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_cmu_mosi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7dbf80e666a6>\u001b[0m in \u001b[0;36mtrain_cmu_mosi\u001b[0;34m(batch_size, epochs, lr, max_rank)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mx_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mx_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cmu_mosi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd9b38-4f2d-4418-883e-7ea793955f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
