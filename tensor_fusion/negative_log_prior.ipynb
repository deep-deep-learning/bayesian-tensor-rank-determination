{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322e43c3-e47a-44f9-9f88-9f24f3fcee4c",
   "metadata": {},
   "source": [
    "Negative log likelihood loss\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/negative-log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df0828-9a6b-4568-9602-dc772134c5bf",
   "metadata": {},
   "source": [
    "Trying to implement the negative log loss for the priors\n",
    "\n",
    "$p(\\theta)=p(\\lambda)\\prod_n p(U^{(n)}|\\lambda)$\\\n",
    "$\\ \\ \\ \\ \\ \\ \\ =\\prod_j p(\\lambda_j) \\prod_n \\prod_{i,j} \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j)$\n",
    "\n",
    "$\\ \\ \\ -\\log p(\\theta)$\\\n",
    "$= -\\log \\left( \\prod_j p(\\lambda_j) \\prod_n \\prod_{i,j} \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j) \\right)$\\\n",
    "$= -\\left( \\sum_j \\log p(\\lambda_j) + \\sum_n \\sum_{i,j} \\log \\mathcal N(u_{i,j}^{(n)}|0,\\lambda_j) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "412f1f20-3717-4283-9abc-931306018151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import halfcauchy, loguniform, norm, truncnorm\n",
    "import numpy as np\n",
    "\n",
    "from torch.distributions.half_cauchy import HalfCauchy\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datasets import Multimodal_Binary_Dataset\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from model import SubNet, TextSubNet\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edeb5dbe-2bbf-4c9d-b5d6-25e310fee7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptive_CP_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, output_size, max_rank):\n",
    "        \n",
    "        super(Adaptive_CP_Linear, self).__init__()\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        shape = input_sizes + (output_size,)\n",
    "        self.weight = CP(shape, max_rank)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        y = 1.0\n",
    "        for i, x in enumerate(inputs):\n",
    "            y = y * (x @ self.weight.factors[i])\n",
    "        y = y @ self.weight.factors[-1].T\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b30da4f6-b74d-4c6d-bbf0-df4db49e9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape, max_rank, prior_type='log_uniform', eta=None):\n",
    "        \n",
    "        super(CP, self).__init__()\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.order = len(shape)\n",
    "        self.max_rank = max_rank\n",
    "        self.prior_type = prior_type\n",
    "        \n",
    "        self.factors = nn.ParameterList([nn.init.xavier_normal_(nn.Parameter(torch.empty(s, max_rank)))\n",
    "                                         for s in shape])\n",
    "        \n",
    "        self.rank_params = nn.Parameter(torch.rand(max_rank))\n",
    "        \n",
    "    def log_priors(self):\n",
    "        \n",
    "        log_priors = 0.0\n",
    "        \n",
    "        rank_params_dist = HalfCauchy(1.0)\n",
    "        log_priors += rank_params_dist.log_prob(self.rank_params).sum()\n",
    "        \n",
    "        factors_dist = Normal(0, self.rank_params)\n",
    "        for f in self.factors:\n",
    "            log_priors += factors_dist.log_prob(f).sum()\n",
    "        \n",
    "        return log_priors\n",
    "    '''\n",
    "    def init_factors(self):\n",
    "        \n",
    "        target_stddev = np.sqrt(2/np.prod(self.shape[:-1]))\n",
    "        factor_stddev = np.power(target_stddev / self.max_rank, 1 / self.order)\n",
    "        init_dist = truncnorm(a=-3.0*factor_stddev, b=3.0*factor_stddev, \n",
    "                              loc=0.0, scale=factor_stddev)\n",
    "        for s in self.shape:\n",
    "            self.factors.append(nn.Parameter(torch.tensor(init_dist.rvs((s, self.max_rank)), \n",
    "                                                          dtype=torch.float32)))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17ccbab5-d3c7-49e9-bf58-914b6ccc170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cmu_mosi(batch_size=32, epochs=100, lr=.001, max_rank=20):\n",
    "\n",
    "    # load dataset file\n",
    "    file = open('../../dataset/cmu-mosi/mosi_20_seq_data.pkl', 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # prepare the datasets and data loaders\n",
    "    train_set = Multimodal_Binary_Dataset(data['train']['text'], data['train']['audio'],\n",
    "                                  data['train']['vision'], data['train']['labels'])\n",
    "    valid_set = Multimodal_Binary_Dataset(data['valid']['text'], data['valid']['audio'],\n",
    "                                  data['valid']['vision'], data['valid']['labels'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "\n",
    "    # set up model\n",
    "    input_sizes = (train_set[0][0]['audio'].shape[0], train_set[0][0]['vision'].shape[0],\n",
    "                   train_set[0][0]['text'].shape[1])\n",
    "    hidden_sizes = (32, 32, 128)\n",
    "    output_size = 1\n",
    "    \n",
    "    model = CP_Tensor_Fusion_Network(input_sizes, hidden_sizes, output_size, max_rank)\n",
    "    \n",
    "    # set up training\n",
    "    DTYPE = torch.FloatTensor\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # train and validate\n",
    "    for e in range(1, epochs + 1):\n",
    "        # train\n",
    "        tic = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            features, label = batch\n",
    "            \n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            \n",
    "            output = model([x_a, x_v, x_t])\n",
    "            nll_loss = criterion(output, y)\n",
    "            \n",
    "            loss = nll_loss - model.tensor_fusion_layer.weight.log_priors()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        print(train_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38c0ad0f-33de-427f-8c47-fd9509d822ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_Tensor_Fusion_Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_sizes, hidden_sizes, output_size, max_rank):\n",
    "\n",
    "        super(CP_Tensor_Fusion_Network, self).__init__()\n",
    "\n",
    "        self.input_sizes = input_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.max_rank = max_rank\n",
    "        \n",
    "        self.audio_subnet = SubNet(input_sizes[0], hidden_sizes[0], dropout=0.3)\n",
    "        self.video_subnet = SubNet(input_sizes[1], hidden_sizes[1], dropout=0.3)\n",
    "        self.text_subnet = TextSubNet(input_sizes[2], hidden_sizes[2], hidden_sizes[2], dropout=0.3)\n",
    "        \n",
    "        tensor_input_sizes = (hidden_sizes[0] + 1, hidden_sizes[1] + 1, hidden_sizes[2] + 1)\n",
    "        self.tensor_fusion_layer = Adaptive_CP_Linear(tensor_input_sizes, output_size, max_rank)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # subnet outputs\n",
    "        z_audio = self.audio_subnet(inputs[0])\n",
    "        z_video = self.video_subnet(inputs[1])\n",
    "        z_text = self.text_subnet(inputs[2])\n",
    "\n",
    "        batch_size = z_audio.data.shape[0]\n",
    "\n",
    "        if z_audio.is_cuda:\n",
    "            DTYPE = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            DTYPE = torch.FloatTensor\n",
    "\n",
    "        # 1 in concatenated to each subnet outputs\n",
    "        z_audio = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_audio), dim=1)\n",
    "        z_video = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_video), dim=1)\n",
    "        z_text = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_text), dim=1)\n",
    "\n",
    "        output = self.tensor_fusion_layer([z_audio, z_video, z_text])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c58e1cd-ec13-4187-b395-86690b656fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54271.364990234375\n",
      "37046.089111328125\n",
      "16408.427238464355\n",
      "-10354.333595991135\n",
      "-45804.843017578125\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The value argument must be within the support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-a99603692e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_cmu_mosi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-4e43aaaa0ed5>\u001b[0m in \u001b[0;36mtrain_cmu_mosi\u001b[0;34m(batch_size, epochs, lr, max_rank)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_fusion_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_priors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-499be03ccecc>\u001b[0m in \u001b[0;36mlog_priors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mrank_params_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHalfCauchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlog_priors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrank_params_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfactors_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/distributions/half_cauchy.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         value = torch.as_tensor(value, dtype=self.base_dist.scale.dtype,\n\u001b[1;32m     56\u001b[0m                                 device=self.base_dist.scale.device)\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument must be within the support'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_checked_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The value argument must be within the support"
     ]
    }
   ],
   "source": [
    "train_cmu_mosi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd9b38-4f2d-4418-883e-7ea793955f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
