{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b684eea4-53bf-41f3-bc3d-6293380241e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from model import TFN, LMF, AdaptiveRankFusion\n",
    "from datasets import get_cmu_mosi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c993f7-48eb-4ed3-84ed-656dd5f31bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = get_cmu_mosi_dataset(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97792882-72c9-4a43-8b85-ebef742aa0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian_lee/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "# settings from https://github.com/Justin1904/TensorFusionNetworks/blob/master/train.py\n",
    "input_dims = (5, 20, 300)\n",
    "hidden_dims = (4, 16, 128)\n",
    "text_out = 64\n",
    "dropouts = (0.3, 0.3, 0.3, 0.3)\n",
    "post_fusion_dim = 32\n",
    "model = TFN(input_dims, hidden_dims, text_out, dropouts, post_fusion_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63cbd265-5bd8-43b6-b162-9d0afaac6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "test_dataloader = DataLoader(test_set, batch_size=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48406cc-82d3-4667-8420-1dfbc5de4a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian_lee/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.893936038017273\n",
      "0.6493960022926331\n",
      "Epoch 1\n",
      "23.122301280498505\n",
      "0.5518956184387207\n",
      "Epoch 2\n",
      "19.511977642774582\n",
      "0.5078473091125488\n",
      "Epoch 3\n",
      "17.557215571403503\n",
      "0.536212146282196\n",
      "Epoch 4\n",
      "15.52185334265232\n",
      "0.6276272535324097\n",
      "Epoch 5\n",
      "14.136798739433289\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "0.5497230291366577\n",
      "Epoch 6\n",
      "10.833918131887913\n",
      "0.5712649822235107\n",
      "Epoch 7\n",
      "10.596223138272762\n",
      "0.5716428160667419\n",
      "Epoch 8\n",
      "9.911804616451263\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "0.5686128735542297\n",
      "Epoch 9\n",
      "9.994131349027157\n",
      "0.5700634717941284\n",
      "Epoch 10\n",
      "8.971643168479204\n",
      "0.5718305110931396\n",
      "Epoch 11\n",
      "9.061752662062645\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "0.5769819617271423\n",
      "Epoch 12\n",
      "8.987968303263187\n",
      "0.5768039226531982\n",
      "Epoch 13\n",
      "9.079888701438904\n",
      "0.5773832201957703\n",
      "Epoch 14\n",
      "9.024409659206867\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-07.\n",
      "0.5771111249923706\n",
      "Epoch 15\n",
      "9.136607177555561\n",
      "0.5782935619354248\n",
      "Epoch 16\n",
      "9.564129255712032\n",
      "0.5769394636154175\n",
      "Epoch 17\n",
      "9.126080326735973\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-08.\n",
      "0.5788511633872986\n",
      "Epoch 18\n",
      "9.064451068639755\n",
      "0.5768875479698181\n",
      "Epoch 19\n",
      "8.905423182994127\n",
      "0.580015242099762\n",
      "Epoch 20\n",
      "8.866186924278736\n",
      "0.576813817024231\n",
      "Epoch 21\n",
      "8.909661650657654\n",
      "0.5741700530052185\n",
      "Epoch 22\n",
      "8.84640409052372\n",
      "0.5786093473434448\n",
      "Epoch 23\n",
      "9.351415902376175\n",
      "0.5757254958152771\n",
      "Epoch 24\n",
      "8.846948340535164\n",
      "0.5790191292762756\n",
      "Epoch 25\n",
      "9.020371168851852\n",
      "0.5735369920730591\n",
      "Epoch 26\n",
      "9.110871061682701\n",
      "0.576343297958374\n",
      "Epoch 27\n",
      "8.838832072913647\n",
      "0.5815258622169495\n",
      "Epoch 28\n",
      "9.501542128622532\n",
      "0.579984724521637\n",
      "Epoch 29\n",
      "8.743448242545128\n",
      "0.5762475728988647\n",
      "Epoch 30\n",
      "8.648131035268307\n",
      "0.5792407989501953\n",
      "Epoch 31\n",
      "8.706703901290894\n",
      "0.5764714479446411\n",
      "Epoch 32\n",
      "8.874497026205063\n",
      "0.5778293013572693\n",
      "Epoch 33\n",
      "8.719344556331635\n",
      "0.5793757438659668\n",
      "Epoch 34\n",
      "9.037025213241577\n",
      "0.572594404220581\n",
      "Epoch 35\n",
      "8.816442556679249\n",
      "0.5791641473770142\n",
      "Epoch 36\n",
      "8.924485422670841\n",
      "0.5770940184593201\n",
      "Epoch 37\n",
      "8.82336250692606\n",
      "0.57794588804245\n",
      "Epoch 38\n",
      "8.683962009847164\n",
      "0.5784055590629578\n",
      "Epoch 39\n",
      "8.942541748285294\n",
      "0.5786698460578918\n",
      "Epoch 40\n",
      "9.3800550699234\n",
      "0.5776442289352417\n",
      "Epoch 41\n",
      "9.047809481620789\n",
      "0.5760719180107117\n",
      "Epoch 42\n",
      "9.195458069443703\n",
      "0.5817785859107971\n",
      "Epoch 43\n",
      "8.876755058765411\n",
      "0.5764579772949219\n",
      "Epoch 44\n",
      "9.030999727547169\n",
      "0.5765211582183838\n",
      "Epoch 45\n",
      "8.860148549079895\n",
      "0.5784317255020142\n",
      "Epoch 46\n",
      "8.909817703068256\n",
      "0.5783402323722839\n",
      "Epoch 47\n",
      "9.100396983325481\n",
      "0.5762979984283447\n",
      "Epoch 48\n",
      "9.188856847584248\n",
      "0.5791749954223633\n",
      "Epoch 49\n",
      "9.041226379573345\n",
      "0.5765281319618225\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(list(model.parameters())[2:])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    scheduler.step(valid_loss)\n",
    "    print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ea8d84-7e1f-4908-bec8-334a7e87e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian_lee/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/christian_lee/projects/bayesian-tensor-rank-determination/tensor_fusion/model.py:334: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  xavier_normal(self.audio_factor)\n",
      "/home/christian_lee/projects/bayesian-tensor-rank-determination/tensor_fusion/model.py:335: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  xavier_normal(self.video_factor)\n",
      "/home/christian_lee/projects/bayesian-tensor-rank-determination/tensor_fusion/model.py:336: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  xavier_normal(self.text_factor)\n",
      "/home/christian_lee/projects/bayesian-tensor-rank-determination/tensor_fusion/model.py:337: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  xavier_normal(self.fusion_weights)\n"
     ]
    }
   ],
   "source": [
    "rank = 4\n",
    "output_dim = 1\n",
    "model = LMF(input_dims, hidden_dims, text_out, dropouts, output_dim, rank, use_softmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45bfe104-0bbc-4083-9432-d308a4bc5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "27.718714237213135\n",
      "0.611574649810791\n",
      "Epoch 1\n",
      "24.115648239850998\n",
      "0.5515691637992859\n",
      "Epoch 2\n",
      "21.143627643585205\n",
      "0.5160359740257263\n",
      "Epoch 3\n",
      "19.03038054704666\n",
      "0.4720185101032257\n",
      "Epoch 4\n",
      "16.445132166147232\n",
      "0.4783540666103363\n",
      "Epoch 5\n",
      "14.549745231866837\n",
      "0.47831130027770996\n",
      "Epoch 6\n",
      "13.09028309583664\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch     7: reducing learning rate of group 1 to 1.0000e-04.\n",
      "0.5302578210830688\n",
      "Epoch 7\n",
      "10.462743245065212\n",
      "0.5355609059333801\n",
      "Epoch 8\n",
      "8.853222027420998\n",
      "0.5526226162910461\n",
      "Epoch 9\n",
      "7.827011771500111\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.0000e-05.\n",
      "0.5818965435028076\n",
      "Epoch 10\n",
      "7.516419380903244\n",
      "0.5899335145950317\n",
      "Epoch 11\n",
      "7.578511625528336\n",
      "0.5893776416778564\n",
      "Epoch 12\n",
      "7.438332632184029\n",
      "Epoch    13: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch    13: reducing learning rate of group 1 to 1.0000e-06.\n",
      "0.595984160900116\n",
      "Epoch 13\n",
      "7.352630756795406\n",
      "0.5943298935890198\n",
      "Epoch 14\n",
      "7.313549757003784\n",
      "0.5973531007766724\n",
      "Epoch 15\n",
      "7.20537293702364\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch    16: reducing learning rate of group 1 to 1.0000e-07.\n",
      "0.596371054649353\n",
      "Epoch 16\n",
      "7.288267619907856\n",
      "0.5968474745750427\n",
      "Epoch 17\n",
      "7.103433173149824\n",
      "0.5975185632705688\n",
      "Epoch 18\n",
      "7.7475627437233925\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch    19: reducing learning rate of group 1 to 1.0000e-08.\n",
      "0.5948758125305176\n",
      "Epoch 19\n",
      "7.109756629914045\n",
      "0.5954173803329468\n",
      "Epoch 20\n",
      "7.273914988152683\n",
      "0.5931137800216675\n",
      "Epoch 21\n",
      "7.3348822593688965\n",
      "0.5956448912620544\n",
      "Epoch 22\n",
      "7.297750800848007\n",
      "0.5965915322303772\n",
      "Epoch 23\n",
      "7.385998614132404\n",
      "0.5934643745422363\n",
      "Epoch 24\n",
      "7.298830877989531\n",
      "0.5987247824668884\n",
      "Epoch 25\n",
      "7.045759446918964\n",
      "0.59443598985672\n",
      "Epoch 26\n",
      "7.269432060420513\n",
      "0.5960513353347778\n",
      "Epoch 27\n",
      "7.077184857800603\n",
      "0.5949991345405579\n",
      "Epoch 28\n",
      "7.302279679104686\n",
      "0.5991358160972595\n",
      "Epoch 29\n",
      "7.562191091477871\n",
      "0.5957756042480469\n",
      "Epoch 30\n",
      "7.164697116240859\n",
      "0.5934260487556458\n",
      "Epoch 31\n",
      "7.351068615913391\n",
      "0.597413182258606\n",
      "Epoch 32\n",
      "7.183403454720974\n",
      "0.5946089029312134\n",
      "Epoch 33\n",
      "7.426619738340378\n",
      "0.5981908440589905\n",
      "Epoch 34\n",
      "7.272495936602354\n",
      "0.5979583859443665\n",
      "Epoch 35\n",
      "7.428017012774944\n",
      "0.5930047631263733\n",
      "Epoch 36\n",
      "7.891608290374279\n",
      "0.5936868786811829\n",
      "Epoch 37\n",
      "7.238025275990367\n",
      "0.5969711542129517\n",
      "Epoch 38\n",
      "7.073910530656576\n",
      "0.5959392786026001\n",
      "Epoch 39\n",
      "7.2657730281353\n",
      "0.5964374542236328\n",
      "Epoch 40\n",
      "7.352584276348352\n",
      "0.5983253121376038\n",
      "Epoch 41\n",
      "7.344841919839382\n",
      "0.593689501285553\n",
      "Epoch 42\n",
      "7.2288321098312736\n",
      "0.5962627530097961\n",
      "Epoch 43\n",
      "7.153862386010587\n",
      "0.5982720255851746\n",
      "Epoch 44\n",
      "7.386752609163523\n",
      "0.597156286239624\n",
      "Epoch 45\n",
      "7.430497791618109\n",
      "0.5942853093147278\n",
      "Epoch 46\n",
      "7.222364608198404\n",
      "0.5963059067726135\n",
      "Epoch 47\n",
      "7.534599132835865\n",
      "0.5924394130706787\n",
      "Epoch 48\n",
      "7.233395860064775\n",
      "0.5981927514076233\n",
      "Epoch 49\n",
      "7.206723909825087\n",
      "0.5988249778747559\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "factors = list(model.parameters())[:3]\n",
    "other = list(model.parameters())[3:]\n",
    "factor_lr = 0.0005\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam([{\"params\": factors, \"lr\": factor_lr}, {\"params\": other, \"lr\": lr}])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    scheduler.step(valid_loss)\n",
    "    print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b77167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian_lee/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = AdaptiveRankFusion(input_dims, hidden_dims, dropouts, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0361, grad_fn=<UnbindBackward>),\n",
       " tensor(0.4688, grad_fn=<UnbindBackward>),\n",
       " tensor(0.1688, grad_fn=<UnbindBackward>),\n",
       " tensor(0.7413, grad_fn=<UnbindBackward>),\n",
       " tensor(0.5441, grad_fn=<UnbindBackward>),\n",
       " tensor(0.8754, grad_fn=<UnbindBackward>),\n",
       " tensor(0.3675, grad_fn=<UnbindBackward>),\n",
       " tensor(0.9385, grad_fn=<UnbindBackward>),\n",
       " tensor(0.8079, grad_fn=<UnbindBackward>),\n",
       " tensor(0.3892, grad_fn=<UnbindBackward>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fusion_layer.rank_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e91ce4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Parameter containing:\n",
      "tensor([0.0361, 0.4688, 0.1688, 0.7413, 0.5441, 0.8754, 0.3675, 0.9385, 0.8079,\n",
      "        0.3892], requires_grad=True)\n",
      "3417.6028175354004\n",
      "0.6469851136207581\n",
      "Epoch 1\n",
      "Parameter containing:\n",
      "tensor([0.0531, 0.4481, 0.1869, 0.7207, 0.5235, 0.8548, 0.3468, 0.9180, 0.7873,\n",
      "        0.3685], requires_grad=True)\n",
      "2008.7422065734863\n",
      "0.6123189926147461\n",
      "Epoch 2\n",
      "Parameter containing:\n",
      "tensor([0.0626, 0.4270, 0.1957, 0.6998, 0.5025, 0.8340, 0.3255, 0.8972, 0.7665,\n",
      "        0.3472], requires_grad=True)\n",
      "1478.4829845428467\n",
      "0.582213819026947\n",
      "Epoch 3\n",
      "Parameter containing:\n",
      "tensor([0.0689, 0.4053, 0.1962, 0.6786, 0.4809, 0.8129, 0.3034, 0.8761, 0.7453,\n",
      "        0.3251], requires_grad=True)\n",
      "1128.4907855987549\n",
      "0.5360950231552124\n",
      "Epoch 4\n",
      "Parameter containing:\n",
      "tensor([0.0737, 0.3829, 0.1906, 0.6570, 0.4588, 0.7915, 0.2804, 0.8548, 0.7238,\n",
      "        0.3021], requires_grad=True)\n",
      "839.8427906036377\n",
      "0.5471928119659424\n",
      "Epoch 5\n",
      "Parameter containing:\n",
      "tensor([0.0775, 0.3598, 0.1809, 0.6350, 0.4362, 0.7697, 0.2565, 0.8332, 0.7019,\n",
      "        0.2782], requires_grad=True)\n",
      "571.7776670455933\n",
      "0.5012224912643433\n",
      "Epoch 6\n",
      "Parameter containing:\n",
      "tensor([0.0805, 0.3360, 0.1687, 0.6126, 0.4129, 0.7477, 0.2314, 0.8113, 0.6797,\n",
      "        0.2533], requires_grad=True)\n",
      "307.89253664016724\n",
      "0.5014441013336182\n",
      "Epoch 7\n",
      "Parameter containing:\n",
      "tensor([0.0830, 0.3114, 0.1554, 0.5898, 0.3890, 0.7253, 0.2051, 0.7890, 0.6571,\n",
      "        0.2271], requires_grad=True)\n",
      "35.654080614447594\n",
      "0.4975684583187103\n",
      "Epoch 8\n",
      "Parameter containing:\n",
      "tensor([0.0850, 0.2859, 0.1418, 0.5667, 0.3644, 0.7026, 0.1773, 0.7665, 0.6342,\n",
      "        0.1995], requires_grad=True)\n",
      "-257.098162651062\n",
      "0.5186876654624939\n",
      "Epoch 9\n",
      "Parameter containing:\n",
      "tensor([0.0865, 0.2595, 0.1284, 0.5430, 0.3390, 0.6795, 0.1476, 0.7437, 0.6108,\n",
      "        0.1701], requires_grad=True)\n",
      "-584.8683137893677\n",
      "0.5021238923072815\n",
      "Epoch 10\n",
      "Parameter containing:\n",
      "tensor([0.0877, 0.2319, 0.1154, 0.5190, 0.3128, 0.6560, 0.1154, 0.7206, 0.5870,\n",
      "        0.1384], requires_grad=True)\n",
      "-972.391960144043\n",
      "0.4889630675315857\n",
      "Epoch 11\n",
      "Parameter containing:\n",
      "tensor([0.0886, 0.2031, 0.1030, 0.4944, 0.2855, 0.6322, 0.0796, 0.6971, 0.5627,\n",
      "        0.1035], requires_grad=True)\n",
      "-1470.792444229126\n",
      "0.488234281539917\n",
      "Epoch 12\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.1727, 0.0912, 0.4692, 0.2571, 0.6079, 0.0394, 0.6732, 0.5380,\n",
      "        0.0637], requires_grad=True)\n",
      "-2182.0955924987793\n",
      "0.5051030516624451\n",
      "Epoch 13\n",
      "Parameter containing:\n",
      "tensor([0.0895, 0.1406, 0.0800, 0.4435, 0.2273, 0.5833, 0.0145, 0.6490, 0.5127,\n",
      "        0.0218], requires_grad=True)\n",
      "-3004.382335662842\n",
      "0.563600480556488\n",
      "Epoch 14\n",
      "Parameter containing:\n",
      "tensor([0.0896, 0.1067, 0.0695, 0.4171, 0.1958, 0.5581, 0.0069, 0.6243, 0.4869,\n",
      "        0.0132], requires_grad=True)\n",
      "-3654.1539916992188\n",
      "0.5597716569900513\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch    15: reducing learning rate of group 1 to 5.0000e-05.\n",
      "Epoch 15\n",
      "Parameter containing:\n",
      "tensor([0.0894, 0.0722, 0.0596, 0.3900, 0.1621, 0.5324, 0.0068, 0.5993, 0.4605,\n",
      "        0.0084], requires_grad=True)\n",
      "-3948.6165618896484\n",
      "0.5685567259788513\n",
      "Epoch 16\n",
      "Parameter containing:\n",
      "tensor([0.0893, 0.0691, 0.0586, 0.3873, 0.1586, 0.5299, 0.0068, 0.5968, 0.4578,\n",
      "        0.0084], requires_grad=True)\n",
      "-3989.0488510131836\n",
      "0.5819612145423889\n",
      "Epoch 17\n",
      "Parameter containing:\n",
      "tensor([0.0893, 0.0663, 0.0577, 0.3846, 0.1553, 0.5273, 0.0068, 0.5943, 0.4552,\n",
      "        0.0084], requires_grad=True)\n",
      "-4026.7588272094727\n",
      "0.5827776193618774\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    18: reducing learning rate of group 1 to 5.0000e-06.\n",
      "Epoch 18\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0637, 0.0568, 0.3820, 0.1521, 0.5248, 0.0068, 0.5918, 0.4526,\n",
      "        0.0084], requires_grad=True)\n",
      "-4046.1780395507812\n",
      "0.5886155962944031\n",
      "Epoch 19\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0635, 0.0567, 0.3817, 0.1518, 0.5246, 0.0068, 0.5916, 0.4524,\n",
      "        0.0084], requires_grad=True)\n",
      "-4050.100540161133\n",
      "0.5885202288627625\n",
      "Epoch 20\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0632, 0.0567, 0.3814, 0.1515, 0.5243, 0.0068, 0.5914, 0.4521,\n",
      "        0.0084], requires_grad=True)\n",
      "-4053.103385925293\n",
      "0.5847601294517517\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    21: reducing learning rate of group 1 to 5.0000e-07.\n",
      "Epoch 21\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0630, 0.0566, 0.3812, 0.1512, 0.5241, 0.0068, 0.5911, 0.4519,\n",
      "        0.0084], requires_grad=True)\n",
      "-4054.73543548584\n",
      "0.5871148705482483\n",
      "Epoch 22\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0630, 0.0566, 0.3812, 0.1512, 0.5241, 0.0068, 0.5911, 0.4519,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.754623413086\n",
      "0.5884898900985718\n",
      "Epoch 23\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0566, 0.3812, 0.1512, 0.5240, 0.0068, 0.5911, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.888801574707\n",
      "0.5862545967102051\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    24: reducing learning rate of group 1 to 5.0000e-08.\n",
      "Epoch 24\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.195625305176\n",
      "0.5863381624221802\n",
      "Epoch 25\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.9066162109375\n",
      "0.5891644954681396\n",
      "Epoch 26\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.920700073242\n",
      "0.5896153450012207\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch    27: reducing learning rate of group 1 to 5.0000e-09.\n",
      "Epoch 27\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3992233276367\n",
      "0.5932785272598267\n",
      "Epoch 28\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.808380126953\n",
      "0.5906656980514526\n",
      "Epoch 29\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.0470428466797\n",
      "0.5884739756584167\n",
      "Epoch 30\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3030166625977\n",
      "0.5895824432373047\n",
      "Epoch 31\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.982666015625\n",
      "0.5895335674285889\n",
      "Epoch 32\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.56893157959\n",
      "0.5893284678459167\n",
      "Epoch 33\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.796806335449\n",
      "0.5834758877754211\n",
      "Epoch 34\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.6919860839844\n",
      "0.5902248620986938\n",
      "Epoch 35\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.1727294921875\n",
      "0.5857458710670471\n",
      "Epoch 36\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.482681274414\n",
      "0.5938335657119751\n",
      "Epoch 37\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.645332336426\n",
      "0.5879625678062439\n",
      "Epoch 38\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.198799133301\n",
      "0.5853860974311829\n",
      "Epoch 39\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.4338760375977\n",
      "0.5871192216873169\n",
      "Epoch 40\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.576370239258\n",
      "0.5898057818412781\n",
      "Epoch 41\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.756202697754\n",
      "0.5898866057395935\n",
      "Epoch 42\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.777656555176\n",
      "0.5910518765449524\n",
      "Epoch 43\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.794288635254\n",
      "0.5883781313896179\n",
      "Epoch 44\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.9629974365234\n",
      "0.5874643921852112\n",
      "Epoch 45\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.4551544189453\n",
      "0.5936158895492554\n",
      "Epoch 46\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.009696960449\n",
      "0.5865054726600647\n",
      "Epoch 47\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.7848892211914\n",
      "0.5877548456192017\n",
      "Epoch 48\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.2736587524414\n",
      "0.5913417339324951\n",
      "Epoch 49\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.36678314209\n",
      "0.5868314504623413\n",
      "Epoch 50\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3602752685547\n",
      "0.5873222351074219\n",
      "Epoch 51\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.434242248535\n",
      "0.5902277231216431\n",
      "Epoch 52\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.09725189209\n",
      "0.5891961455345154\n",
      "Epoch 53\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.5631942749023\n",
      "0.5854582190513611\n",
      "Epoch 54\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.320899963379\n",
      "0.5914052724838257\n",
      "Epoch 55\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.7066040039062\n",
      "0.5878946781158447\n",
      "Epoch 56\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.1622772216797\n",
      "0.5850811004638672\n",
      "Epoch 57\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.8279571533203\n",
      "0.5860190987586975\n",
      "Epoch 58\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.338203430176\n",
      "0.5854835510253906\n",
      "Epoch 59\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3202514648438\n",
      "0.5892354249954224\n",
      "Epoch 60\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.8006744384766\n",
      "0.5846174359321594\n",
      "Epoch 61\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.9842834472656\n",
      "0.5882613062858582\n",
      "Epoch 62\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.6641235351562\n",
      "0.5828619003295898\n",
      "Epoch 63\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.5610885620117\n",
      "0.5956024527549744\n",
      "Epoch 64\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.1568145751953\n",
      "0.5897259712219238\n",
      "Epoch 65\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.4514923095703\n",
      "0.587767481803894\n",
      "Epoch 66\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3398056030273\n",
      "0.5871352553367615\n",
      "Epoch 67\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.665184020996\n",
      "0.5894842743873596\n",
      "Epoch 68\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.7486114501953\n",
      "0.5848115682601929\n",
      "Epoch 69\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4057.3435668945312\n",
      "0.5883377194404602\n",
      "Epoch 70\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.087287902832\n",
      "0.5878874063491821\n",
      "Epoch 71\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.2085189819336\n",
      "0.5830899477005005\n",
      "Epoch 72\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.2543411254883\n",
      "0.5902365446090698\n",
      "Epoch 73\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.6571884155273\n",
      "0.5886701941490173\n",
      "Epoch 74\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.025260925293\n",
      "0.5849688649177551\n",
      "Epoch 75\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.029624938965\n",
      "0.5909982323646545\n",
      "Epoch 76\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.41455078125\n",
      "0.586030900478363\n",
      "Epoch 77\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.5220336914062\n",
      "0.5855807662010193\n",
      "Epoch 78\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.9705123901367\n",
      "0.593266487121582\n",
      "Epoch 79\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.9433212280273\n",
      "0.5848757028579712\n",
      "Epoch 80\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.3850708007812\n",
      "0.5935405492782593\n",
      "Epoch 81\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.371925354004\n",
      "0.5911381244659424\n",
      "Epoch 82\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4055.4257049560547\n",
      "0.5879799127578735\n",
      "Epoch 83\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.1148223876953\n",
      "0.5826149582862854\n",
      "Epoch 84\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n",
      "-4056.601387023926\n",
      "0.5887323021888733\n",
      "Epoch 85\n",
      "Parameter containing:\n",
      "tensor([0.0892, 0.0629, 0.0565, 0.3811, 0.1511, 0.5240, 0.0068, 0.5910, 0.4518,\n",
      "        0.0084], requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-606aaefce6e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "factor_lr = 0.0005\n",
    "lr = 0.001\n",
    "subnet_params = list(model.audio_subnet.parameters()) + list(model.video_subnet.parameters()) + list(model.text_subnet.parameters())\n",
    "optimizer = optim.Adam([{\"params\": subnet_params, \"lr\": lr}, \n",
    "                        {\"params\": list(model.fusion_layer.parameters()), \"lr\": factor_lr}])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "epochs = 300\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    print(model.fusion_layer.rank_param)\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label) - 0.1 * model.fusion_layer.get_log_prior()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    print(valid_loss)\n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ca96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0560, 0.3947, 0.4498, 0.4022, 0.3426, 0.5294, 0.5075, 0.6149, 0.6144,\n",
       "        0.5896], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fusion_layer.rank_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94568dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb56fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
