{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b684eea4-53bf-41f3-bc3d-6293380241e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian_lee/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n",
      "  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tensor_fusion.fusion_model import TFN, LMF, AdaptiveRankFusion\n",
    "from tensor_fusion.dataset import get_cmu_mosi_dataset\n",
    "from tensor_fusion.model import AdaptiveRankFactorizedTextSubNet, SubNet\n",
    "from tensor_fusion.fusion_layer import AdaptiveRankFusionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c993f7-48eb-4ed3-84ed-656dd5f31bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "DTYPE=torch.float32\n",
    "train_set, valid_set, test_set = get_cmu_mosi_dataset(binary=True, device=device, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bed9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveRankFusion_with_AdaptiveRankFactorizedTextSubNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_sizes, hidden_sizes, dropouts, output_size, max_rank=10, \n",
    "                 prior_type='half_cauchy', eta=None,\n",
    "                 device=None, dtype=None):\n",
    "        '''\n",
    "        args:\n",
    "            input_sizes: a tuple of ints, (audio_in, video_in, ... text_in)\n",
    "            hidden_sizes: a tuple of ints, (audio_hidden, video_hidden, ... text_hidden)\n",
    "            dropouts: a tuple of floats, (dropout_1, dropout_2, ..., dropout_M, post_fusion_dropout)\n",
    "            output_size: an int, output size for fusion layer\n",
    "            max_rank: an int, maximum rank for the CP decomposition\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the pre-fusion subnetworks\n",
    "        self.audio_subnet = SubNet(input_sizes[0], hidden_sizes[0], dropouts[0], device=device, dtype=dtype)\n",
    "        self.video_subnet = SubNet(input_sizes[1], hidden_sizes[1], dropouts[1], device=device, dtype=dtype)\n",
    "        self.text_subnet = AdaptiveRankFactorizedTextSubNet(input_sizes[2], hidden_sizes[2], hidden_sizes[2]//2, dropout=dropouts[2],\n",
    "                                                            prior_type='half_cauchy', eta=0.01,\n",
    "                                                            device=device, dtype=dtype)\n",
    "        \n",
    "        fusion_input_sizes = (hidden_sizes[0]+1, hidden_sizes[1]+1, hidden_sizes[2]//2+1)\n",
    "        # define fusion layer\n",
    "        self.fusion_layer = AdaptiveRankFusionLayer(input_sizes=fusion_input_sizes,\n",
    "                                                    output_size=output_size,\n",
    "                                                    max_rank=max_rank,\n",
    "                                                    prior_type=prior_type,\n",
    "                                                    eta=eta,\n",
    "                                                    device=device,\n",
    "                                                    dtype=dtype)\n",
    "\n",
    "        self.post_fusion_dropout = nn.Dropout(dropouts[-1])\n",
    "\n",
    "    def forward(self, audio_x, video_x, text_x):\n",
    "\n",
    "        audio_h = self.audio_subnet(audio_x)\n",
    "        video_h = self.video_subnet(video_x)\n",
    "        text_h = self.text_subnet(text_x)\n",
    "\n",
    "        batch_size = audio_h.shape[0]\n",
    "        device = audio_h.device\n",
    "        dtype = audio_h.dtype\n",
    "\n",
    "        audio_h = torch.cat((audio_h, torch.ones((batch_size, 1), device=device, dtype=dtype)), dim=1)\n",
    "        video_h = torch.cat((video_h, torch.ones((batch_size, 1), device=device, dtype=dtype)), dim=1)\n",
    "        text_h = torch.cat((text_h, torch.ones((batch_size, 1), device=device, dtype=dtype)), dim=1)\n",
    "\n",
    "        output = self.fusion_layer([audio_h, video_h, text_h])\n",
    "        output = self.post_fusion_dropout(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b77167",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "input_dims = (5, 20, 300)\n",
    "hidden_dims = (4, 16, 128)\n",
    "text_out = 64\n",
    "dropouts = (0.3, 0.3, 0.3, 0.3)\n",
    "rank = 4\n",
    "output_dim = 1\n",
    "model = AdaptiveRankFusion_with_AdaptiveRankFactorizedTextSubNet(input_dims, hidden_dims, dropouts, output_size=1, max_rank=10, prior_type='half_cauchy', eta=0.01, device='cuda', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63cbd265-5bd8-43b6-b162-9d0afaac6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "test_dataloader = DataLoader(test_set, batch_size=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91ce4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Parameter containing:\n",
      "tensor([[0.2673, 0.2653, 0.2732, 0.2667, 0.2371, 0.2714, 0.2846, 0.2828, 0.2606,\n",
      "         0.3198]], device='cuda:0', requires_grad=True)\n",
      "28.854748487472534\n",
      "0.6867510080337524\n",
      "Epoch 1\n",
      "Parameter containing:\n",
      "tensor([[0.2445, 0.2425, 0.2506, 0.2438, 0.2144, 0.2488, 0.2620, 0.2601, 0.2380,\n",
      "         0.2971]], device='cuda:0', requires_grad=True)\n",
      "28.52066946029663\n",
      "0.68100905418396\n",
      "Epoch 2\n",
      "Parameter containing:\n",
      "tensor([[0.2151, 0.2130, 0.2211, 0.2143, 0.1850, 0.2194, 0.2332, 0.2316, 0.2086,\n",
      "         0.2675]], device='cuda:0', requires_grad=True)\n",
      "28.019900143146515\n",
      "0.6663017272949219\n",
      "Epoch 3\n",
      "Parameter containing:\n",
      "tensor([[0.1841, 0.1818, 0.1899, 0.1832, 0.1541, 0.1884, 0.2038, 0.2053, 0.1775,\n",
      "         0.2364]], device='cuda:0', requires_grad=True)\n",
      "27.23625671863556\n",
      "0.6478971838951111\n",
      "Epoch 4\n",
      "Parameter containing:\n",
      "tensor([[0.1530, 0.1502, 0.1582, 0.1516, 0.1230, 0.1575, 0.1771, 0.1889, 0.1460,\n",
      "         0.2048]], device='cuda:0', requires_grad=True)\n",
      "26.691229701042175\n",
      "0.6409147381782532\n",
      "Epoch 5\n",
      "Parameter containing:\n",
      "tensor([[0.1222, 0.1185, 0.1265, 0.1201, 0.0922, 0.1270, 0.1533, 0.1772, 0.1148,\n",
      "         0.1733]], device='cuda:0', requires_grad=True)\n",
      "25.772428035736084\n",
      "0.6188545227050781\n",
      "Epoch 6\n",
      "Parameter containing:\n",
      "tensor([[0.0923, 0.0868, 0.0948, 0.0888, 0.0625, 0.0983, 0.1361, 0.1684, 0.0847,\n",
      "         0.1422]], device='cuda:0', requires_grad=True)\n",
      "25.096393048763275\n",
      "0.6168978214263916\n",
      "Epoch 7\n",
      "Parameter containing:\n",
      "tensor([[0.0644, 0.0547, 0.0629, 0.0576, 0.0352, 0.0746, 0.1284, 0.1689, 0.0569,\n",
      "         0.1121]], device='cuda:0', requires_grad=True)\n",
      "24.363987922668457\n",
      "0.5862382054328918\n",
      "Epoch 8\n",
      "Parameter containing:\n",
      "tensor([[0.0408, 0.0210, 0.0306, 0.0260, 0.0140, 0.0608, 0.1233, 0.1638, 0.0349,\n",
      "         0.0838]], device='cuda:0', requires_grad=True)\n",
      "24.27990671992302\n",
      "0.5944293737411499\n",
      "Epoch 9\n",
      "Parameter containing:\n",
      "tensor([[0.0238, 0.0075, 0.0042, 0.0018, 0.0070, 0.0543, 0.1218, 0.1640, 0.0197,\n",
      "         0.0609]], device='cuda:0', requires_grad=True)\n",
      "24.72669094800949\n",
      "0.5788027048110962\n",
      "Epoch 10\n",
      "Parameter containing:\n",
      "tensor([[0.0049, 0.0087, 0.0078, 0.0038, 0.0061, 0.0480, 0.1186, 0.1604, 0.0038,\n",
      "         0.0482]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5eaf0c5c27f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.0001\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfusion_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor_layers/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "factor_lr = 0.0005\n",
    "lr = 0.001\n",
    "subnet_params = list(model.audio_subnet.parameters()) + list(model.video_subnet.parameters()) + list(model.text_subnet.parameters())\n",
    "optimizer = optim.Adam([{\"params\": subnet_params, \"lr\": lr}, \n",
    "                        {\"params\": list(model.fusion_layer.parameters()), \"lr\": factor_lr}])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "epochs = 300\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    print(model.fusion_layer.weight_tensor.rank_parameter)\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label) - 0.0001 * model.fusion_layer.get_log_prior()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    print(valid_loss)\n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b044ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bcbb71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fusion_layer.weight_tensor.factors[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97792882-72c9-4a43-8b85-ebef742aa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "# settings from https://github.com/Justin1904/TensorFusionNetworks/blob/master/train.py\n",
    "input_dims = (5, 20, 300)\n",
    "hidden_dims = (4, 16, 128)\n",
    "text_out = 64\n",
    "dropouts = (0.3, 0.3, 0.3, 0.3)\n",
    "post_fusion_dim = 32\n",
    "model = TFN(input_dims, hidden_dims, text_out, dropouts, post_fusion_dim, device=device, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48406cc-82d3-4667-8420-1dfbc5de4a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "27.746791183948517\n",
      "0.5983000993728638\n",
      "Epoch 1\n",
      "22.599841356277466\n",
      "0.5741891860961914\n",
      "Epoch 2\n",
      "20.9776431620121\n",
      "0.5182520747184753\n",
      "Epoch 3\n",
      "18.447107419371605\n",
      "0.5316178798675537\n",
      "Epoch 4\n",
      "16.16508023440838\n",
      "0.5781940817832947\n",
      "Epoch 5\n",
      "13.750149548053741\n",
      "0.5866302847862244\n",
      "Epoch 6\n",
      "12.41133339703083\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "0.5868079662322998\n",
      "Epoch 7\n",
      "9.790406368672848\n",
      "0.6064910292625427\n",
      "Epoch 8\n",
      "9.155158430337906\n",
      "0.6138084530830383\n",
      "Epoch 9\n",
      "8.670896269381046\n",
      "0.6321585178375244\n",
      "Epoch 10\n",
      "8.77745607495308\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-05.\n",
      "0.6368790864944458\n",
      "Epoch 11\n",
      "8.624453119933605\n",
      "0.6399129629135132\n",
      "Epoch 12\n",
      "8.29000923037529\n",
      "0.6426395177841187\n",
      "Epoch 13\n",
      "8.115225300192833\n",
      "0.6466211080551147\n",
      "Epoch 14\n",
      "7.943665310740471\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-06.\n",
      "0.64751797914505\n",
      "Epoch 15\n",
      "7.860414206981659\n",
      "0.6442150473594666\n",
      "Epoch 16\n",
      "8.334999352693558\n",
      "0.6477405428886414\n",
      "Epoch 17\n",
      "7.960166782140732\n",
      "0.6489644646644592\n",
      "Epoch 18\n",
      "8.140599392354488\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-07.\n",
      "0.6492005586624146\n",
      "Epoch 19\n",
      "8.172261871397495\n",
      "0.6479445695877075\n",
      "Epoch 20\n",
      "8.08784906566143\n",
      "0.6462928652763367\n",
      "Epoch 21\n",
      "8.334032654762268\n",
      "0.6469361782073975\n",
      "Epoch 22\n",
      "8.73171516507864\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-08.\n",
      "0.6508252024650574\n",
      "Epoch 23\n",
      "7.981371037662029\n",
      "0.6473308801651001\n",
      "Epoch 24\n",
      "8.417544722557068\n",
      "0.648343026638031\n",
      "Epoch 25\n",
      "8.031305737793446\n",
      "0.6459775567054749\n",
      "Epoch 26\n",
      "8.12254523485899\n",
      "0.6453434824943542\n",
      "Epoch 27\n",
      "8.03839984536171\n",
      "0.6498525738716125\n",
      "Epoch 28\n",
      "8.85992294549942\n",
      "0.6441264152526855\n",
      "Epoch 29\n",
      "7.967857874929905\n",
      "0.6472366452217102\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(list(model.parameters())[2:])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    scheduler.step(valid_loss)\n",
    "    print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ea8d84-7e1f-4908-bec8-334a7e87e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "# settings from https://github.com/Justin1904/TensorFusionNetworks/blob/master/train.py\n",
    "input_dims = (5, 20, 300)\n",
    "hidden_dims = (4, 16, 128)\n",
    "text_out = 64\n",
    "dropouts = (0.3, 0.3, 0.3, 0.3)\n",
    "rank = 4\n",
    "output_dim = 1\n",
    "model = LMF(input_dims, hidden_dims, text_out, dropouts, output_dim, rank, use_softmax=False, device=device, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bfe104-0bbc-4083-9432-d308a4bc5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "27.707884550094604\n",
      "0.6103724837303162\n",
      "Epoch 1\n",
      "25.751307010650635\n",
      "0.5993456244468689\n",
      "Epoch 2\n",
      "21.946386218070984\n",
      "0.506530225276947\n",
      "Epoch 3\n",
      "19.738655865192413\n",
      "0.5119958519935608\n",
      "Epoch 4\n",
      "17.642503082752228\n",
      "0.4785168170928955\n",
      "Epoch 5\n",
      "16.091687828302383\n",
      "0.5398954153060913\n",
      "Epoch 6\n",
      "14.24790771305561\n",
      "0.5091980695724487\n",
      "Epoch 7\n",
      "11.752081230282784\n",
      "0.49786096811294556\n",
      "Epoch 8\n",
      "10.936970323324203\n",
      "0.6509965658187866\n",
      "Epoch 9\n",
      "8.470754906535149\n",
      "0.7462157011032104\n",
      "Epoch 10\n",
      "6.700329817831516\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch    11: reducing learning rate of group 1 to 1.0000e-04.\n",
      "0.6205970048904419\n",
      "Epoch 11\n",
      "4.487218387424946\n",
      "0.656859278678894\n",
      "Epoch 12\n",
      "4.011319886893034\n",
      "0.7138518691062927\n",
      "Epoch 13\n",
      "2.7622850690968335\n",
      "0.7538882493972778\n",
      "Epoch 14\n",
      "2.608662152197212\n",
      "0.8387965559959412\n",
      "Epoch 15\n",
      "2.2656643863301724\n",
      "0.8688085675239563\n",
      "Epoch 16\n",
      "1.9815785735845566\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch    17: reducing learning rate of group 1 to 1.0000e-05.\n",
      "0.9243594408035278\n",
      "Epoch 17\n",
      "1.6791507564485073\n",
      "0.9393513202667236\n",
      "Epoch 18\n",
      "1.7685941588133574\n",
      "0.9345608949661255\n",
      "Epoch 19\n",
      "1.7583383307792246\n",
      "0.9677313566207886\n",
      "Epoch 20\n",
      "1.75196064542979\n",
      "0.9492374658584595\n",
      "Epoch 21\n",
      "1.825397544344014\n",
      "0.9664304256439209\n",
      "Epoch 22\n",
      "1.7335525159724057\n",
      "Epoch    23: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch    23: reducing learning rate of group 1 to 1.0000e-06.\n",
      "0.9677141308784485\n",
      "Epoch 23\n",
      "1.74197110068053\n",
      "0.95294189453125\n",
      "Epoch 24\n",
      "1.7200385006144643\n",
      "0.9830134510993958\n",
      "Epoch 25\n",
      "1.7982194949872792\n",
      "0.9908159375190735\n",
      "Epoch 26\n",
      "1.6173386545706308\n",
      "0.9754800796508789\n",
      "Epoch 27\n",
      "1.6996030984446406\n",
      "0.9746277928352356\n",
      "Epoch 28\n",
      "1.5848018452525139\n",
      "Epoch    29: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch    29: reducing learning rate of group 1 to 1.0000e-07.\n",
      "0.9767020344734192\n",
      "Epoch 29\n",
      "1.5750283543020487\n",
      "0.9661332368850708\n",
      "Epoch 30\n",
      "1.5704402626724914\n",
      "0.978689968585968\n",
      "Epoch 31\n",
      "1.6026200745254755\n",
      "0.9728176593780518\n",
      "Epoch 32\n",
      "1.639820363605395\n",
      "0.9758750796318054\n",
      "Epoch 33\n",
      "1.525914203375578\n",
      "0.9851778149604797\n",
      "Epoch 34\n",
      "1.5822293520905077\n",
      "Epoch    35: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch    35: reducing learning rate of group 1 to 1.0000e-08.\n",
      "0.9746446013450623\n",
      "Epoch 35\n",
      "1.6975648775696754\n",
      "0.9765679240226746\n",
      "Epoch 36\n",
      "1.4931691320380196\n",
      "0.9687380790710449\n",
      "Epoch 37\n",
      "2.0934471655637026\n",
      "0.9876952767372131\n",
      "Epoch 38\n",
      "1.6249587764032185\n",
      "0.9693502187728882\n",
      "Epoch 39\n",
      "1.6170653048320673\n",
      "0.9794011116027832\n",
      "Epoch 40\n",
      "1.6219410235062242\n",
      "0.9696405529975891\n",
      "Epoch 41\n",
      "1.7185707516036928\n",
      "0.966849684715271\n",
      "Epoch 42\n",
      "1.550655295373872\n",
      "0.9706491827964783\n",
      "Epoch 43\n",
      "1.7266184007748961\n",
      "0.9628940224647522\n",
      "Epoch 44\n",
      "1.764770170673728\n",
      "0.9762403964996338\n",
      "Epoch 45\n",
      "1.5595343066379428\n",
      "0.9689929485321045\n",
      "Epoch 46\n",
      "1.6857039481401443\n",
      "0.9723986387252808\n",
      "Epoch 47\n",
      "1.8188751999259694\n",
      "0.9693955779075623\n",
      "Epoch 48\n",
      "1.6188694995071273\n",
      "0.9975922107696533\n",
      "Epoch 49\n",
      "1.593727805186063\n",
      "0.968612551689148\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "factors = list(model.parameters())[:3]\n",
    "other = list(model.parameters())[3:]\n",
    "factor_lr = 0.0005\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam([{\"params\": factors, \"lr\": factor_lr}, {\"params\": other, \"lr\": lr}])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}'.format(e))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for text, audio, vision, label in train_dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(audio, vision, text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    for text, audio, vision, label in valid_dataloader:\n",
    "        output = model(audio, vision, text)\n",
    "        valid_loss = criterion(output, label).item()\n",
    "    scheduler.step(valid_loss)\n",
    "    print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d4335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fusion_layer.weight_tensor.factors[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0361, grad_fn=<UnbindBackward>),\n",
       " tensor(0.4688, grad_fn=<UnbindBackward>),\n",
       " tensor(0.1688, grad_fn=<UnbindBackward>),\n",
       " tensor(0.7413, grad_fn=<UnbindBackward>),\n",
       " tensor(0.5441, grad_fn=<UnbindBackward>),\n",
       " tensor(0.8754, grad_fn=<UnbindBackward>),\n",
       " tensor(0.3675, grad_fn=<UnbindBackward>),\n",
       " tensor(0.9385, grad_fn=<UnbindBackward>),\n",
       " tensor(0.8079, grad_fn=<UnbindBackward>),\n",
       " tensor(0.3892, grad_fn=<UnbindBackward>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fusion_layer.rank_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ca96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0560, 0.3947, 0.4498, 0.4022, 0.3426, 0.5294, 0.5075, 0.6149, 0.6144,\n",
       "        0.5896], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fusion_layer.rank_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94568dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb56fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
