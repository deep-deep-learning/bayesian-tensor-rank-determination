{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24b9113-2384-489c-9df1-5c110bfd7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from model import SubNet, TextSubNet, TFN\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fbb5d4-ed6f-4173-8840-f46db232a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_Linear_Function(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x_1, x_2, x_3, W_1, W_2, W_3, W_y):\n",
    "        \n",
    "        A_1 = x_1 @ W_1\n",
    "        A_2 = x_2 @ W_2\n",
    "        A_3 = x_3 @ W_3\n",
    "        \n",
    "        A_f = A_1 * A_2 * A_3\n",
    "        \n",
    "        y_hat = A_f @ W_y.T\n",
    "        \n",
    "        ctx.save_for_backward(x_1, x_2, x_3, W_1, W_2, W_3, W_y, A_1, A_2, A_3, A_f)\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y_hat):\n",
    "        \n",
    "        x_1, x_2, x_3, W_1, W_2, W_3, W_y, A_1, A_2, A_3, A_f = ctx.saved_tensors\n",
    "        \n",
    "        grad_x_1 = grad_x_2 = grad_x_3 = grad_W_1 = grad_W_2 = grad_W_3 = grad_W_y = None\n",
    "        \n",
    "        grad_W_y = grad_y_hat.T @ A_f\n",
    "        \n",
    "        grad_A_f = grad_y_hat @ W_y\n",
    "        \n",
    "        grad_A_1 = grad_A_f * A_2 * A_3\n",
    "        grad_A_2 = grad_A_f * A_1 * A_3\n",
    "        grad_A_3 = grad_A_f * A_1 * A_2\n",
    "        \n",
    "        grad_W_1 = x_1.T @ grad_A_1\n",
    "        grad_W_2 = x_2.T @ grad_A_2\n",
    "        grad_W_3 = x_3.T @ grad_A_3\n",
    "        \n",
    "        grad_x_1 = grad_A_1 @ W_1.T\n",
    "        grad_x_2 = grad_A_2 @ W_2.T\n",
    "        grad_x_3 = grad_A_3 @ W_3.T\n",
    "        \n",
    "        return grad_x_1, grad_x_2, grad_x_3, grad_W_1, grad_W_2, grad_W_3, grad_W_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6f2297-d0cb-4134-bbee-f8bba7561b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, output_size, rank):\n",
    "        \n",
    "        super(CP_Linear, self).__init__()\n",
    "        \n",
    "        self.W_1 = nn.Parameter(torch.rand((input_sizes[0], rank)))\n",
    "        self.W_2 = nn.Parameter(torch.rand((input_sizes[1], rank)))\n",
    "        self.W_3 = nn.Parameter(torch.rand((input_sizes[2], rank)))\n",
    "        self.W_y = nn.Parameter(torch.rand((output_size, rank)))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        return CP_Linear_Function.apply(inputs[0], inputs[1], inputs[2], \n",
    "                                        self.W_1, self.W_2, self.W_3, self.W_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e7ad6-981a-4609-89cb-4a16530e8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_Fixed_Rank_Tensor_Fusion_Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, hidden_sizes, output_size, rank):\n",
    "        \n",
    "        super(CP_Fixed_Rank_Tensor_Fusion_Network, self).__init__()\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.rank = rank\n",
    "        \n",
    "        self.audio_subnet = SubNet(input_sizes[0], hidden_sizes[0], dropout=0.3)\n",
    "        self.video_subnet = SubNet(input_sizes[1], hidden_sizes[1], dropout=0.3)\n",
    "        self.text_subnet = TextSubNet(input_sizes[2], hidden_sizes[2], hidden_sizes[2], \n",
    "                                      dropout=0.3)\n",
    "        \n",
    "        fusion_input_shape = (hidden_sizes[0]+1, hidden_sizes[1]+1, hidden_sizes[2]+1)\n",
    "        self.tensor_fusion_layer = CP_Linear(fusion_input_shape, output_size, rank)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        z_audio = self.audio_subnet(inputs[0])\n",
    "        z_video = self.video_subnet(inputs[1])\n",
    "        z_text = self.text_subnet(inputs[2])\n",
    "        \n",
    "        batch_size = z_audio.data.shape[0]\n",
    "        \n",
    "        if z_audio.is_cuda:\n",
    "            DTYPE = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            DTYPE = torch.FloatTensor\n",
    "        \n",
    "        # 1 in concatenated to each subnet outputs\n",
    "        z_audio = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_audio), dim=1)\n",
    "        z_video = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_video), dim=1)\n",
    "        z_text = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_text), dim=1)\n",
    "        \n",
    "        output = self.tensor_fusion_layer([z_audio, z_video, z_text])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48e8088-9789-4507-adc0-d886c0037170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMF(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sizes, hidden_sizes, output_size, rank):\n",
    "        \n",
    "        super(LMF, self).__init__()\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.rank = rank\n",
    "        \n",
    "        self.audio_subnet = SubNet(input_sizes[0], hidden_sizes[0], dropout=0.3)\n",
    "        self.video_subnet = SubNet(input_sizes[1], hidden_sizes[1], dropout=0.3)\n",
    "        self.text_subnet = TextSubNet(input_sizes[2], hidden_sizes[2], hidden_sizes[2], \n",
    "                                      dropout=0.3)\n",
    "        \n",
    "        self.W_1 = nn.Parameter(torch.rand((hidden_sizes[0]+1, rank)))\n",
    "        self.W_2 = nn.Parameter(torch.rand((hidden_sizes[1]+1, rank)))\n",
    "        self.W_3 = nn.Parameter(torch.rand((hidden_sizes[2]+1, rank)))\n",
    "        self.W_y = nn.Parameter(torch.rand((output_size, rank)))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "                \n",
    "        z_audio = self.audio_subnet(inputs[0])\n",
    "        z_video = self.video_subnet(inputs[1])\n",
    "        z_text = self.text_subnet(inputs[2])\n",
    "        \n",
    "        batch_size = z_audio.data.shape[0]\n",
    "        \n",
    "        if z_audio.is_cuda:\n",
    "            DTYPE = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            DTYPE = torch.FloatTensor\n",
    "        \n",
    "        # 1 in concatenated to each subnet outputs\n",
    "        z_audio = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_audio), dim=1)\n",
    "        z_video = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_video), dim=1)\n",
    "        z_text = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), z_text), dim=1)\n",
    "        \n",
    "        A_1 = z_audio @ self.W_1\n",
    "        A_2 = z_video @ self.W_2\n",
    "        A_3 = z_text @ self.W_3\n",
    "        \n",
    "        A_f = A_1 * A_2 * A_3\n",
    "        \n",
    "        output = A_f @ self.W_y.T\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fbcd1f-d2ba-4698-aa5e-b57a7fe45e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    '''\n",
    "    Dataset for CMU-MOSI\n",
    "    '''\n",
    "    def __init__(self, text, audio, vision, labels):\n",
    "        '''\n",
    "        args:\n",
    "            text: text modality feature of shape (N, seq. length, text_input_size)\n",
    "            audio: audio modality feature of shape (N, seq. length, audio_input_size)\n",
    "            vision: vision modality feature of shape (N, seq. length, vision_input_size)\n",
    "            labels: labels of shape (N, 1) and ranges from -3 to 3\n",
    "        '''\n",
    "        self.text = text\n",
    "        self.audio = audio\n",
    "        self.vision = vision\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Returns an individual data composed of (features, label)\n",
    "        where features is a dictionary {'text': , 'audio':, 'vision':}\n",
    "\n",
    "        Returns:\n",
    "            features['text']: text modality feature of shape (seq. length, text_input_size)\n",
    "            features['audio']: audio modality feature of shape (audio_input_size)\n",
    "            features['vision']: vision modality feature of shape (vision_input_size)\n",
    "\n",
    "            label: a scalar label that ranges from -3 to 3\n",
    "        '''\n",
    "        features = dict()\n",
    "        features['text'] = self.text[idx]\n",
    "        # audio and vision features are averaged across time\n",
    "        features['audio'] = np.mean(self.audio[idx], axis=0)\n",
    "        features['vision'] = np.mean(self.vision[idx], axis=0)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c545bf0d-c644-4723-8d80-c44cc6fdd288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_rank_train_CMU_mosi(model_type, batch_size=32, epochs=100, max_rank=20, lr=.001):\n",
    "\n",
    "    # load dataset file\n",
    "    file = open('mosi_20_seq_data.pkl', 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # prepare the datasets and data loaders\n",
    "    train_set = MultimodalDataset(data['train']['text'], data['train']['audio'],\n",
    "                                  data['train']['vision'], data['train']['labels'])\n",
    "    valid_set = MultimodalDataset(data['valid']['text'], data['valid']['audio'],\n",
    "                                  data['valid']['vision'], data['valid']['labels'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_set, batch_size=len(valid_set))\n",
    "\n",
    "    # set up model\n",
    "    input_sizes = (train_set[0][0]['audio'].shape[0], train_set[0][0]['vision'].shape[0],\n",
    "                   train_set[0][0]['text'].shape[1])\n",
    "    hidden_sizes = (32, 32, 128)\n",
    "    output_size = 1\n",
    "    \n",
    "    if model_type == 'custom':\n",
    "        model = CP_Fixed_Rank_Tensor_Fusion_Network(input_sizes, hidden_sizes, output_size, max_rank)\n",
    "    elif model_type == 'pytorch':\n",
    "        model = LMF(input_sizes, hidden_sizes, output_size, max_rank)\n",
    "    elif model_type == 'full':\n",
    "        model = TFN(input_sizes, hidden_sizes, 64, (0.3, 0.3, 0.3, 0.0), 32)\n",
    "    \n",
    "    # set up training\n",
    "    DTYPE = torch.FloatTensor\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = nn.MSELoss(size_average=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_times = []\n",
    "    valid_errors = []\n",
    "    \n",
    "    # train and validate\n",
    "    for e in range(1, epochs + 1):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        for batch in train_dataloader:\n",
    "            model.zero_grad()\n",
    "\n",
    "            features, label = batch\n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            \n",
    "            if model_type == 'full':\n",
    "                output = model(x_a, x_v, x_t)\n",
    "            else:\n",
    "                output = model([x_a, x_v, x_t])\n",
    "\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() / len(train_set)\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_time = time.time() - start\n",
    "        \n",
    "        print(\"Epoch {}\".format(e))\n",
    "        print(\"Training Loss {:.2f}\".format(train_loss))\n",
    "        print(\"Training Time {:.2f}\".format(train_time))\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_times.append(train_time)\n",
    "        \n",
    "        # validate\n",
    "        model.eval()\n",
    "        for batch in valid_dataloader:\n",
    "            features, label = batch\n",
    "            x_a = Variable(features['audio'].float().type(DTYPE), requires_grad=False)\n",
    "            x_v = Variable(features['vision'].float().type(DTYPE), requires_grad=False)\n",
    "            x_t = Variable(features['text'].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(label.view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "\n",
    "            output = model([x_a, x_v, x_t])\n",
    "\n",
    "        output_valid = output.detach().numpy().reshape(-1)\n",
    "        y = y.numpy().reshape(-1)\n",
    "\n",
    "        # validation mean squared error\n",
    "        valid_mse = mean_squared_error(output_valid, y)\n",
    "        print(\"Validation MSE {:.2f}\".format(valid_mse))\n",
    "        \n",
    "        valid_errors.append(valid_mse)\n",
    "        \n",
    "    np.savetxt('train_losses.csv', train_losses, delimiter=',')\n",
    "    np.savetxt('train_times.csv', train_times, delimiter=',')\n",
    "    np.savetxt('valid_errors.csv', valid_errors, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e4f642-20e7-45bf-8f60-65cf87450883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss 2.03\n",
      "Training Time 1.31\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'video_x' and 'text_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_145307/1057768503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfixed_rank_train_CMU_mosi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_145307/3365474270.py\u001b[0m in \u001b[0;36mfixed_rank_train_CMU_mosi\u001b[0;34m(model_type, batch_size, epochs, max_rank, lr)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutput_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'video_x' and 'text_x'"
     ]
    }
   ],
   "source": [
    "fixed_rank_train_CMU_mosi(model_type='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6c1ffc-dc1f-4209-b79e-f708dc59818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/yifan/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss 79.94\n",
      "Training Time 0.39\n",
      "Validation MSE 4.20\n",
      "Epoch 2\n",
      "Training Loss 3.98\n",
      "Training Time 0.38\n",
      "Validation MSE 2.88\n",
      "Epoch 3\n",
      "Training Loss 2.88\n",
      "Training Time 0.37\n",
      "Validation MSE 2.64\n",
      "Epoch 4\n",
      "Training Loss 2.30\n",
      "Training Time 0.37\n",
      "Validation MSE 2.48\n",
      "Epoch 5\n",
      "Training Loss 2.12\n",
      "Training Time 0.37\n",
      "Validation MSE 2.40\n",
      "Epoch 6\n",
      "Training Loss 2.03\n",
      "Training Time 0.41\n",
      "Validation MSE 2.35\n",
      "Epoch 7\n",
      "Training Loss 1.91\n",
      "Training Time 0.40\n",
      "Validation MSE 2.36\n",
      "Epoch 8\n",
      "Training Loss 1.87\n",
      "Training Time 0.38\n",
      "Validation MSE 2.28\n",
      "Epoch 9\n",
      "Training Loss 1.81\n",
      "Training Time 0.38\n",
      "Validation MSE 2.25\n",
      "Epoch 10\n",
      "Training Loss 1.74\n",
      "Training Time 0.38\n",
      "Validation MSE 2.23\n",
      "Epoch 11\n",
      "Training Loss 1.77\n",
      "Training Time 0.38\n",
      "Validation MSE 2.20\n",
      "Epoch 12\n",
      "Training Loss 1.66\n",
      "Training Time 0.37\n",
      "Validation MSE 2.18\n",
      "Epoch 13\n",
      "Training Loss 1.63\n",
      "Training Time 0.37\n",
      "Validation MSE 2.17\n",
      "Epoch 14\n",
      "Training Loss 1.58\n",
      "Training Time 0.38\n",
      "Validation MSE 2.13\n",
      "Epoch 15\n",
      "Training Loss 1.58\n",
      "Training Time 0.39\n",
      "Validation MSE 2.10\n",
      "Epoch 16\n",
      "Training Loss 1.54\n",
      "Training Time 0.39\n",
      "Validation MSE 2.07\n",
      "Epoch 17\n",
      "Training Loss 1.50\n",
      "Training Time 0.39\n",
      "Validation MSE 2.04\n",
      "Epoch 18\n",
      "Training Loss 1.47\n",
      "Training Time 0.39\n",
      "Validation MSE 2.01\n",
      "Epoch 19\n",
      "Training Loss 1.42\n",
      "Training Time 0.39\n",
      "Validation MSE 1.97\n",
      "Epoch 20\n",
      "Training Loss 1.37\n",
      "Training Time 0.39\n",
      "Validation MSE 1.93\n",
      "Epoch 21\n",
      "Training Loss 1.36\n",
      "Training Time 0.39\n",
      "Validation MSE 1.88\n",
      "Epoch 22\n",
      "Training Loss 1.29\n",
      "Training Time 0.37\n",
      "Validation MSE 1.85\n",
      "Epoch 23\n",
      "Training Loss 1.28\n",
      "Training Time 0.37\n",
      "Validation MSE 1.81\n",
      "Epoch 24\n",
      "Training Loss 1.24\n",
      "Training Time 0.38\n",
      "Validation MSE 1.83\n",
      "Epoch 25\n",
      "Training Loss 1.22\n",
      "Training Time 0.39\n",
      "Validation MSE 1.75\n",
      "Epoch 26\n",
      "Training Loss 1.16\n",
      "Training Time 0.39\n",
      "Validation MSE 1.72\n",
      "Epoch 27\n",
      "Training Loss 1.13\n",
      "Training Time 0.39\n",
      "Validation MSE 1.71\n",
      "Epoch 28\n",
      "Training Loss 1.07\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 29\n",
      "Training Loss 1.05\n",
      "Training Time 0.38\n",
      "Validation MSE 1.65\n",
      "Epoch 30\n",
      "Training Loss 1.02\n",
      "Training Time 0.39\n",
      "Validation MSE 1.66\n",
      "Epoch 31\n",
      "Training Loss 1.00\n",
      "Training Time 0.39\n",
      "Validation MSE 1.66\n",
      "Epoch 32\n",
      "Training Loss 0.98\n",
      "Training Time 0.39\n",
      "Validation MSE 1.66\n",
      "Epoch 33\n",
      "Training Loss 0.89\n",
      "Training Time 0.38\n",
      "Validation MSE 1.66\n",
      "Epoch 34\n",
      "Training Loss 0.92\n",
      "Training Time 0.38\n",
      "Validation MSE 1.63\n",
      "Epoch 35\n",
      "Training Loss 0.84\n",
      "Training Time 0.38\n",
      "Validation MSE 1.73\n",
      "Epoch 36\n",
      "Training Loss 0.87\n",
      "Training Time 0.39\n",
      "Validation MSE 1.90\n",
      "Epoch 37\n",
      "Training Loss 0.94\n",
      "Training Time 0.39\n",
      "Validation MSE 1.63\n",
      "Epoch 38\n",
      "Training Loss 0.79\n",
      "Training Time 0.38\n",
      "Validation MSE 1.63\n",
      "Epoch 39\n",
      "Training Loss 0.79\n",
      "Training Time 0.38\n",
      "Validation MSE 1.63\n",
      "Epoch 40\n",
      "Training Loss 0.75\n",
      "Training Time 0.38\n",
      "Validation MSE 1.61\n",
      "Epoch 41\n",
      "Training Loss 0.74\n",
      "Training Time 0.38\n",
      "Validation MSE 1.64\n",
      "Epoch 42\n",
      "Training Loss 0.73\n",
      "Training Time 0.37\n",
      "Validation MSE 1.62\n",
      "Epoch 43\n",
      "Training Loss 0.66\n",
      "Training Time 0.37\n",
      "Validation MSE 1.66\n",
      "Epoch 44\n",
      "Training Loss 0.69\n",
      "Training Time 0.37\n",
      "Validation MSE 1.67\n",
      "Epoch 45\n",
      "Training Loss 0.61\n",
      "Training Time 0.38\n",
      "Validation MSE 1.68\n",
      "Epoch 46\n",
      "Training Loss 0.61\n",
      "Training Time 0.37\n",
      "Validation MSE 1.66\n",
      "Epoch 47\n",
      "Training Loss 0.59\n",
      "Training Time 0.38\n",
      "Validation MSE 1.69\n",
      "Epoch 48\n",
      "Training Loss 0.57\n",
      "Training Time 0.37\n",
      "Validation MSE 1.66\n",
      "Epoch 49\n",
      "Training Loss 0.53\n",
      "Training Time 0.38\n",
      "Validation MSE 1.68\n",
      "Epoch 50\n",
      "Training Loss 0.52\n",
      "Training Time 0.38\n",
      "Validation MSE 1.69\n",
      "Epoch 51\n",
      "Training Loss 0.52\n",
      "Training Time 0.38\n",
      "Validation MSE 1.78\n",
      "Epoch 52\n",
      "Training Loss 0.55\n",
      "Training Time 0.38\n",
      "Validation MSE 1.70\n",
      "Epoch 53\n",
      "Training Loss 0.47\n",
      "Training Time 0.37\n",
      "Validation MSE 1.72\n",
      "Epoch 54\n",
      "Training Loss 0.45\n",
      "Training Time 0.37\n",
      "Validation MSE 1.70\n",
      "Epoch 55\n",
      "Training Loss 0.43\n",
      "Training Time 0.37\n",
      "Validation MSE 1.69\n",
      "Epoch 56\n",
      "Training Loss 0.42\n",
      "Training Time 0.37\n",
      "Validation MSE 1.71\n",
      "Epoch 57\n",
      "Training Loss 0.41\n",
      "Training Time 0.37\n",
      "Validation MSE 1.71\n",
      "Epoch 58\n",
      "Training Loss 0.41\n",
      "Training Time 0.37\n",
      "Validation MSE 1.73\n",
      "Epoch 59\n",
      "Training Loss 0.41\n",
      "Training Time 0.39\n",
      "Validation MSE 1.73\n",
      "Epoch 60\n",
      "Training Loss 0.36\n",
      "Training Time 0.41\n",
      "Validation MSE 1.74\n",
      "Epoch 61\n",
      "Training Loss 0.36\n",
      "Training Time 0.42\n",
      "Validation MSE 1.84\n",
      "Epoch 62\n",
      "Training Loss 0.42\n",
      "Training Time 0.37\n",
      "Validation MSE 1.69\n",
      "Epoch 63\n",
      "Training Loss 0.38\n",
      "Training Time 0.41\n",
      "Validation MSE 1.77\n",
      "Epoch 64\n",
      "Training Loss 0.35\n",
      "Training Time 0.42\n",
      "Validation MSE 1.73\n",
      "Epoch 65\n",
      "Training Loss 0.34\n",
      "Training Time 0.41\n",
      "Validation MSE 1.70\n",
      "Epoch 66\n",
      "Training Loss 0.30\n",
      "Training Time 0.40\n",
      "Validation MSE 1.75\n",
      "Epoch 67\n",
      "Training Loss 0.34\n",
      "Training Time 0.42\n",
      "Validation MSE 1.72\n",
      "Epoch 68\n",
      "Training Loss 0.31\n",
      "Training Time 0.45\n",
      "Validation MSE 1.74\n",
      "Epoch 69\n",
      "Training Loss 0.30\n",
      "Training Time 0.38\n",
      "Validation MSE 1.68\n",
      "Epoch 70\n",
      "Training Loss 0.27\n",
      "Training Time 0.38\n",
      "Validation MSE 1.76\n",
      "Epoch 71\n",
      "Training Loss 0.30\n",
      "Training Time 0.38\n",
      "Validation MSE 1.72\n",
      "Epoch 72\n",
      "Training Loss 0.30\n",
      "Training Time 0.37\n",
      "Validation MSE 1.70\n",
      "Epoch 73\n",
      "Training Loss 0.26\n",
      "Training Time 0.38\n",
      "Validation MSE 1.73\n",
      "Epoch 74\n",
      "Training Loss 0.26\n",
      "Training Time 0.37\n",
      "Validation MSE 1.78\n",
      "Epoch 75\n",
      "Training Loss 0.32\n",
      "Training Time 0.37\n",
      "Validation MSE 1.80\n",
      "Epoch 76\n",
      "Training Loss 0.23\n",
      "Training Time 0.39\n",
      "Validation MSE 1.73\n",
      "Epoch 77\n",
      "Training Loss 0.23\n",
      "Training Time 0.44\n",
      "Validation MSE 1.73\n",
      "Epoch 78\n",
      "Training Loss 0.24\n",
      "Training Time 0.37\n",
      "Validation MSE 1.75\n",
      "Epoch 79\n",
      "Training Loss 0.24\n",
      "Training Time 0.37\n",
      "Validation MSE 1.79\n",
      "Epoch 80\n",
      "Training Loss 0.24\n",
      "Training Time 0.37\n",
      "Validation MSE 1.71\n",
      "Epoch 81\n",
      "Training Loss 0.23\n",
      "Training Time 0.37\n",
      "Validation MSE 1.80\n",
      "Epoch 82\n",
      "Training Loss 0.23\n",
      "Training Time 0.37\n",
      "Validation MSE 1.78\n",
      "Epoch 83\n",
      "Training Loss 0.23\n",
      "Training Time 0.37\n",
      "Validation MSE 1.88\n",
      "Epoch 84\n",
      "Training Loss 0.20\n",
      "Training Time 0.38\n",
      "Validation MSE 1.75\n",
      "Epoch 85\n",
      "Training Loss 0.19\n",
      "Training Time 0.38\n",
      "Validation MSE 1.77\n",
      "Epoch 86\n",
      "Training Loss 0.21\n",
      "Training Time 0.38\n",
      "Validation MSE 1.73\n",
      "Epoch 87\n",
      "Training Loss 0.20\n",
      "Training Time 0.42\n",
      "Validation MSE 1.75\n",
      "Epoch 88\n",
      "Training Loss 0.19\n",
      "Training Time 0.38\n",
      "Validation MSE 1.75\n",
      "Epoch 89\n",
      "Training Loss 0.18\n",
      "Training Time 0.39\n",
      "Validation MSE 1.78\n",
      "Epoch 90\n",
      "Training Loss 0.19\n",
      "Training Time 0.38\n",
      "Validation MSE 1.77\n",
      "Epoch 91\n",
      "Training Loss 0.19\n",
      "Training Time 0.38\n",
      "Validation MSE 1.77\n",
      "Epoch 92\n",
      "Training Loss 0.16\n",
      "Training Time 0.37\n",
      "Validation MSE 1.78\n",
      "Epoch 93\n",
      "Training Loss 0.16\n",
      "Training Time 0.38\n",
      "Validation MSE 1.80\n",
      "Epoch 94\n",
      "Training Loss 0.18\n",
      "Training Time 0.37\n",
      "Validation MSE 1.78\n",
      "Epoch 95\n",
      "Training Loss 0.16\n",
      "Training Time 0.41\n",
      "Validation MSE 1.80\n",
      "Epoch 96\n",
      "Training Loss 0.18\n",
      "Training Time 0.37\n",
      "Validation MSE 1.77\n",
      "Epoch 97\n",
      "Training Loss 0.18\n",
      "Training Time 0.37\n",
      "Validation MSE 1.88\n",
      "Epoch 98\n",
      "Training Loss 0.17\n",
      "Training Time 0.37\n",
      "Validation MSE 1.81\n",
      "Epoch 99\n",
      "Training Loss 0.18\n",
      "Training Time 0.37\n",
      "Validation MSE 1.77\n",
      "Epoch 100\n",
      "Training Loss 0.13\n",
      "Training Time 0.38\n",
      "Validation MSE 1.78\n"
     ]
    }
   ],
   "source": [
    "fixed_rank_train_CMU_mosi(model_type='pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac261c4e-df71-456b-a101-5c86b4e29f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/yifan/anaconda3/envs/TensorFusion/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss 36.29\n",
      "Training Time 0.41\n",
      "Validation MSE 3.31\n",
      "Epoch 2\n",
      "Training Loss 3.10\n",
      "Training Time 0.40\n",
      "Validation MSE 2.64\n",
      "Epoch 3\n",
      "Training Loss 2.54\n",
      "Training Time 0.39\n",
      "Validation MSE 2.47\n",
      "Epoch 4\n",
      "Training Loss 2.27\n",
      "Training Time 0.38\n",
      "Validation MSE 2.42\n",
      "Epoch 5\n",
      "Training Loss 2.04\n",
      "Training Time 0.38\n",
      "Validation MSE 2.28\n",
      "Epoch 6\n",
      "Training Loss 1.92\n",
      "Training Time 0.38\n",
      "Validation MSE 2.23\n",
      "Epoch 7\n",
      "Training Loss 1.84\n",
      "Training Time 0.44\n",
      "Validation MSE 2.30\n",
      "Epoch 8\n",
      "Training Loss 1.80\n",
      "Training Time 0.41\n",
      "Validation MSE 2.13\n",
      "Epoch 9\n",
      "Training Loss 1.69\n",
      "Training Time 0.41\n",
      "Validation MSE 2.09\n",
      "Epoch 10\n",
      "Training Loss 1.62\n",
      "Training Time 0.45\n",
      "Validation MSE 2.05\n",
      "Epoch 11\n",
      "Training Loss 1.53\n",
      "Training Time 0.38\n",
      "Validation MSE 2.06\n",
      "Epoch 12\n",
      "Training Loss 1.50\n",
      "Training Time 0.38\n",
      "Validation MSE 1.94\n",
      "Epoch 13\n",
      "Training Loss 1.41\n",
      "Training Time 0.38\n",
      "Validation MSE 1.89\n",
      "Epoch 14\n",
      "Training Loss 1.35\n",
      "Training Time 0.38\n",
      "Validation MSE 1.90\n",
      "Epoch 15\n",
      "Training Loss 1.29\n",
      "Training Time 0.38\n",
      "Validation MSE 1.86\n",
      "Epoch 16\n",
      "Training Loss 1.23\n",
      "Training Time 0.37\n",
      "Validation MSE 1.85\n",
      "Epoch 17\n",
      "Training Loss 1.20\n",
      "Training Time 0.40\n",
      "Validation MSE 1.87\n",
      "Epoch 18\n",
      "Training Loss 1.14\n",
      "Training Time 0.38\n",
      "Validation MSE 1.75\n",
      "Epoch 19\n",
      "Training Loss 1.09\n",
      "Training Time 0.38\n",
      "Validation MSE 1.78\n",
      "Epoch 20\n",
      "Training Loss 1.05\n",
      "Training Time 0.38\n",
      "Validation MSE 1.69\n",
      "Epoch 21\n",
      "Training Loss 1.02\n",
      "Training Time 0.40\n",
      "Validation MSE 1.71\n",
      "Epoch 22\n",
      "Training Loss 1.02\n",
      "Training Time 0.38\n",
      "Validation MSE 1.68\n",
      "Epoch 23\n",
      "Training Loss 0.96\n",
      "Training Time 0.39\n",
      "Validation MSE 1.68\n",
      "Epoch 24\n",
      "Training Loss 0.92\n",
      "Training Time 0.37\n",
      "Validation MSE 1.86\n",
      "Epoch 25\n",
      "Training Loss 0.88\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 26\n",
      "Training Loss 0.85\n",
      "Training Time 0.40\n",
      "Validation MSE 1.81\n",
      "Epoch 27\n",
      "Training Loss 0.82\n",
      "Training Time 0.38\n",
      "Validation MSE 1.66\n",
      "Epoch 28\n",
      "Training Loss 0.79\n",
      "Training Time 0.41\n",
      "Validation MSE 1.67\n",
      "Epoch 29\n",
      "Training Loss 0.77\n",
      "Training Time 0.41\n",
      "Validation MSE 1.68\n",
      "Epoch 30\n",
      "Training Loss 0.69\n",
      "Training Time 0.41\n",
      "Validation MSE 1.63\n",
      "Epoch 31\n",
      "Training Loss 0.72\n",
      "Training Time 0.38\n",
      "Validation MSE 1.67\n",
      "Epoch 32\n",
      "Training Loss 0.63\n",
      "Training Time 0.38\n",
      "Validation MSE 1.70\n",
      "Epoch 33\n",
      "Training Loss 0.70\n",
      "Training Time 0.38\n",
      "Validation MSE 1.67\n",
      "Epoch 34\n",
      "Training Loss 0.62\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 35\n",
      "Training Loss 0.58\n",
      "Training Time 0.38\n",
      "Validation MSE 1.84\n",
      "Epoch 36\n",
      "Training Loss 0.54\n",
      "Training Time 0.38\n",
      "Validation MSE 1.67\n",
      "Epoch 37\n",
      "Training Loss 0.53\n",
      "Training Time 0.39\n",
      "Validation MSE 1.67\n",
      "Epoch 38\n",
      "Training Loss 0.52\n",
      "Training Time 0.39\n",
      "Validation MSE 1.66\n",
      "Epoch 39\n",
      "Training Loss 0.50\n",
      "Training Time 0.38\n",
      "Validation MSE 1.72\n",
      "Epoch 40\n",
      "Training Loss 0.45\n",
      "Training Time 0.38\n",
      "Validation MSE 1.70\n",
      "Epoch 41\n",
      "Training Loss 0.45\n",
      "Training Time 0.38\n",
      "Validation MSE 1.76\n",
      "Epoch 42\n",
      "Training Loss 0.51\n",
      "Training Time 0.38\n",
      "Validation MSE 1.73\n",
      "Epoch 43\n",
      "Training Loss 0.44\n",
      "Training Time 0.42\n",
      "Validation MSE 1.81\n",
      "Epoch 44\n",
      "Training Loss 0.41\n",
      "Training Time 0.41\n",
      "Validation MSE 1.75\n",
      "Epoch 45\n",
      "Training Loss 0.40\n",
      "Training Time 0.37\n",
      "Validation MSE 1.72\n",
      "Epoch 46\n",
      "Training Loss 0.41\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 47\n",
      "Training Loss 0.38\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 48\n",
      "Training Loss 0.40\n",
      "Training Time 0.38\n",
      "Validation MSE 1.89\n",
      "Epoch 49\n",
      "Training Loss 0.41\n",
      "Training Time 0.38\n",
      "Validation MSE 1.78\n",
      "Epoch 50\n",
      "Training Loss 0.35\n",
      "Training Time 0.38\n",
      "Validation MSE 1.70\n",
      "Epoch 51\n",
      "Training Loss 0.32\n",
      "Training Time 0.38\n",
      "Validation MSE 1.74\n",
      "Epoch 52\n",
      "Training Loss 0.34\n",
      "Training Time 0.38\n",
      "Validation MSE 1.88\n",
      "Epoch 53\n",
      "Training Loss 0.35\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 54\n",
      "Training Loss 0.27\n",
      "Training Time 0.40\n",
      "Validation MSE 1.73\n",
      "Epoch 55\n",
      "Training Loss 0.28\n",
      "Training Time 0.42\n",
      "Validation MSE 1.76\n",
      "Epoch 56\n",
      "Training Loss 0.27\n",
      "Training Time 0.40\n",
      "Validation MSE 1.74\n",
      "Epoch 57\n",
      "Training Loss 0.25\n",
      "Training Time 0.42\n",
      "Validation MSE 1.75\n",
      "Epoch 58\n",
      "Training Loss 0.23\n",
      "Training Time 0.41\n",
      "Validation MSE 1.80\n",
      "Epoch 59\n",
      "Training Loss 0.25\n",
      "Training Time 0.37\n",
      "Validation MSE 1.89\n",
      "Epoch 60\n",
      "Training Loss 0.24\n",
      "Training Time 0.39\n",
      "Validation MSE 1.78\n",
      "Epoch 61\n",
      "Training Loss 0.24\n",
      "Training Time 0.39\n",
      "Validation MSE 1.76\n",
      "Epoch 62\n",
      "Training Loss 0.24\n",
      "Training Time 0.39\n",
      "Validation MSE 1.75\n",
      "Epoch 63\n",
      "Training Loss 0.22\n",
      "Training Time 0.38\n",
      "Validation MSE 1.80\n",
      "Epoch 64\n",
      "Training Loss 0.22\n",
      "Training Time 0.39\n",
      "Validation MSE 1.75\n",
      "Epoch 65\n",
      "Training Loss 0.25\n",
      "Training Time 0.38\n",
      "Validation MSE 1.89\n",
      "Epoch 66\n",
      "Training Loss 0.21\n",
      "Training Time 0.40\n",
      "Validation MSE 1.80\n",
      "Epoch 67\n",
      "Training Loss 0.19\n",
      "Training Time 0.40\n",
      "Validation MSE 1.79\n",
      "Epoch 68\n",
      "Training Loss 0.20\n",
      "Training Time 0.40\n",
      "Validation MSE 1.78\n",
      "Epoch 69\n",
      "Training Loss 0.19\n",
      "Training Time 0.40\n",
      "Validation MSE 1.79\n",
      "Epoch 70\n",
      "Training Loss 0.19\n",
      "Training Time 0.40\n",
      "Validation MSE 1.87\n",
      "Epoch 71\n",
      "Training Loss 0.18\n",
      "Training Time 0.38\n",
      "Validation MSE 1.78\n",
      "Epoch 72\n",
      "Training Loss 0.17\n",
      "Training Time 0.38\n",
      "Validation MSE 1.80\n",
      "Epoch 73\n",
      "Training Loss 0.19\n",
      "Training Time 0.39\n",
      "Validation MSE 1.80\n",
      "Epoch 74\n",
      "Training Loss 0.19\n",
      "Training Time 0.38\n",
      "Validation MSE 1.71\n",
      "Epoch 75\n",
      "Training Loss 0.18\n",
      "Training Time 0.38\n",
      "Validation MSE 1.79\n",
      "Epoch 76\n",
      "Training Loss 0.19\n",
      "Training Time 0.39\n",
      "Validation MSE 1.80\n",
      "Epoch 77\n",
      "Training Loss 0.18\n",
      "Training Time 0.38\n",
      "Validation MSE 1.79\n",
      "Epoch 78\n",
      "Training Loss 0.16\n",
      "Training Time 0.40\n",
      "Validation MSE 1.76\n",
      "Epoch 79\n",
      "Training Loss 0.15\n",
      "Training Time 0.40\n",
      "Validation MSE 1.84\n",
      "Epoch 80\n",
      "Training Loss 0.15\n",
      "Training Time 0.39\n",
      "Validation MSE 1.76\n",
      "Epoch 81\n",
      "Training Loss 0.15\n",
      "Training Time 0.40\n",
      "Validation MSE 1.81\n",
      "Epoch 82\n",
      "Training Loss 0.14\n",
      "Training Time 0.40\n",
      "Validation MSE 1.76\n",
      "Epoch 83\n",
      "Training Loss 0.14\n",
      "Training Time 0.40\n",
      "Validation MSE 1.75\n",
      "Epoch 84\n",
      "Training Loss 0.16\n",
      "Training Time 0.39\n",
      "Validation MSE 1.74\n",
      "Epoch 85\n",
      "Training Loss 0.16\n",
      "Training Time 0.39\n",
      "Validation MSE 1.78\n",
      "Epoch 86\n",
      "Training Loss 0.13\n",
      "Training Time 0.39\n",
      "Validation MSE 1.80\n",
      "Epoch 87\n",
      "Training Loss 0.15\n",
      "Training Time 0.41\n",
      "Validation MSE 1.85\n",
      "Epoch 88\n",
      "Training Loss 0.13\n",
      "Training Time 0.39\n",
      "Validation MSE 1.78\n",
      "Epoch 89\n",
      "Training Loss 0.14\n",
      "Training Time 0.41\n",
      "Validation MSE 1.81\n",
      "Epoch 90\n",
      "Training Loss 0.13\n",
      "Training Time 0.40\n",
      "Validation MSE 1.69\n",
      "Epoch 91\n",
      "Training Loss 0.12\n",
      "Training Time 0.39\n",
      "Validation MSE 1.79\n",
      "Epoch 92\n",
      "Training Loss 0.13\n",
      "Training Time 0.38\n",
      "Validation MSE 1.77\n",
      "Epoch 93\n",
      "Training Loss 0.12\n",
      "Training Time 0.39\n",
      "Validation MSE 1.77\n",
      "Epoch 94\n",
      "Training Loss 0.11\n",
      "Training Time 0.38\n",
      "Validation MSE 1.81\n",
      "Epoch 95\n",
      "Training Loss 0.14\n",
      "Training Time 0.38\n",
      "Validation MSE 1.86\n",
      "Epoch 96\n",
      "Training Loss 0.12\n",
      "Training Time 0.39\n",
      "Validation MSE 1.78\n",
      "Epoch 97\n",
      "Training Loss 0.12\n",
      "Training Time 0.38\n",
      "Validation MSE 1.84\n",
      "Epoch 98\n",
      "Training Loss 0.11\n",
      "Training Time 0.39\n",
      "Validation MSE 1.71\n",
      "Epoch 99\n",
      "Training Loss 0.10\n",
      "Training Time 0.40\n",
      "Validation MSE 1.76\n",
      "Epoch 100\n",
      "Training Loss 0.10\n",
      "Training Time 0.39\n",
      "Validation MSE 1.73\n"
     ]
    }
   ],
   "source": [
    "fixed_rank_train_CMU_mosi(model_type='custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad502d6-3985-414f-945d-9e8e03cfce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "input_sizes = (10, 20, 30)\n",
    "output_size = 2\n",
    "batch_size = 64\n",
    "X_1 = torch.rand((batch_size, input_sizes[0]))\n",
    "X_2 = torch.rand((batch_size, input_sizes[1]))\n",
    "X_3 = torch.rand((batch_size, input_sizes[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc5f860-4142-4be4-8165-20582c60f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = CP_Linear(input_sizes, output_size, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84501b8e-3ed5-4e46-a4b2-7ea47de32fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = layer([X_1, X_2, X_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46023ea1-c44a-42ef-af2b-0a37edba417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones((batch_size, output_size))\n",
    "loss = torch.mean((y - y_hat)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80cc9f9-0c70-4b51-a17f-f7f56bb3137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47703/18384497.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_1 = torch.tensor(layer.W_1.clone().detach(), requires_grad=True)\n",
      "/tmp/ipykernel_47703/18384497.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_2 = torch.tensor(layer.W_2.clone().detach(), requires_grad=True)\n",
      "/tmp/ipykernel_47703/18384497.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_3 = torch.tensor(layer.W_3.clone().detach(), requires_grad=True)\n",
      "/tmp/ipykernel_47703/18384497.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W_y = torch.tensor(layer.W_y.clone().detach(), requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W_1 = torch.tensor(layer.W_1.clone().detach(), requires_grad=True)\n",
    "W_2 = torch.tensor(layer.W_2.clone().detach(), requires_grad=True)\n",
    "W_3 = torch.tensor(layer.W_3.clone().detach(), requires_grad=True)\n",
    "W_y = torch.tensor(layer.W_y.clone().detach(), requires_grad=True)\n",
    "\n",
    "A_1 = X_1 @ W_1\n",
    "A_2 = X_2 @ W_2\n",
    "A_3 = X_3 @ W_3\n",
    "A_1.retain_grad()\n",
    "A_2.retain_grad()\n",
    "A_3.retain_grad()\n",
    "\n",
    "A_f = A_1 * A_2 * A_3\n",
    "A_f.retain_grad()\n",
    "\n",
    "y_hat = A_f @ W_y.T\n",
    "y_hat.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79fd993c-f044-435a-97a4-ee7fa576d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((y - y_hat)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd392aa2-9d45-4593-8f93-e83caaab811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0005,  0.0000,  0.0000,  0.0000,  0.0002,  0.0000,  0.0000, -0.0005,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0010,  0.0000,  0.0000,  0.0000,  0.0000,  0.0005,\n",
       "         -0.0005,  0.0000],\n",
       "        [ 0.0000, -0.0010, -0.0010, -0.0001, -0.0002,  0.0005,  0.0000,  0.0000,\n",
       "          0.0005,  0.0002],\n",
       "        [ 0.0000,  0.0000, -0.0010,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0005],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.0001, -0.0002,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0005,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0002, -0.0005,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0020,  0.0000, -0.0002,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0005,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0010,  0.0000,  0.0000,  0.0002,  0.0000, -0.0010,  0.0005,\n",
       "         -0.0005,  0.0005],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.W_1.grad - W_1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd80702-9fe5-4626-b5d0-6ed2fd861969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  4.8828e-04,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  2.4414e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -4.8828e-04, -6.1035e-05,  1.2207e-04,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00, -4.8828e-04,  0.0000e+00,  1.2207e-04,\n",
       "          2.4414e-04,  0.0000e+00, -2.4414e-04,  2.4414e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2207e-04,  0.0000e+00,\n",
       "          0.0000e+00,  2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -2.4414e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  4.8828e-04,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.8828e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4414e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  4.8828e-04,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  2.4414e-04,  0.0000e+00,  2.4414e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  4.8828e-04, -6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4414e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4414e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2207e-04,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04,  0.0000e+00],\n",
       "        [-2.4414e-04,  0.0000e+00, -4.8828e-04,  0.0000e+00,  1.2207e-04,\n",
       "         -2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  4.8828e-04,  0.0000e+00,  6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.4414e-04,  0.0000e+00,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4414e-04,  0.0000e+00,  2.4414e-04,  0.0000e+00,  1.2207e-04,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04,  1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4414e-04],\n",
       "        [ 0.0000e+00,  4.8828e-04,  0.0000e+00,  0.0000e+00,  1.2207e-04,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.W_2.grad - W_2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd4b6d1f-2816-4cec-b511-3018906eb869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4414e-04,  0.0000e+00,  0.0000e+00, -3.0518e-05,  6.1035e-05,\n",
       "         -1.2207e-04,  1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.8828e-04,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0518e-05,  0.0000e+00,\n",
       "          0.0000e+00,  2.4414e-04,  0.0000e+00,  2.4414e-04, -1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.8828e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.2207e-04,  0.0000e+00,  2.4414e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1035e-05,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1035e-05, -6.1035e-05,\n",
       "          0.0000e+00, -1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1035e-05,\n",
       "          0.0000e+00,  0.0000e+00,  1.2207e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  4.8828e-04,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00, -2.4414e-04, -1.2207e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  4.8828e-04,  0.0000e+00,  6.1035e-05, -6.1035e-05,\n",
       "          0.0000e+00,  0.0000e+00, -1.2207e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1035e-05,\n",
       "          1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.2207e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -2.4414e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.2207e-04,  1.2207e-04,  0.0000e+00,  0.0000e+00, -1.2207e-04],\n",
       "        [ 0.0000e+00,  4.8828e-04,  0.0000e+00,  0.0000e+00, -6.1035e-05,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4414e-04, -1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0518e-05,  0.0000e+00,\n",
       "          0.0000e+00,  1.2207e-04,  0.0000e+00, -2.4414e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0518e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.8828e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.2207e-04,  0.0000e+00,  0.0000e+00,  6.1035e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1035e-05,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04,  1.2207e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "          1.2207e-04,  1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -4.8828e-04,  0.0000e+00],\n",
       "        [-2.4414e-04,  4.8828e-04, -2.4414e-04,  0.0000e+00,  0.0000e+00,\n",
       "          1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4414e-04, -4.8828e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4414e-04,  0.0000e+00],\n",
       "        [ 2.4414e-04,  0.0000e+00,  2.4414e-04,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.2207e-04,  1.2207e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.4414e-04,  0.0000e+00,  0.0000e+00,\n",
       "         -1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  2.4414e-04,  6.1035e-05,  0.0000e+00,\n",
       "          0.0000e+00,  1.2207e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.W_3.grad - W_3.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52989a26-afe1-4f4e-a00e-2be9fe9cd36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.W_y.grad - W_y.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
