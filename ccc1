Using CPU...
model arch:
mlp top arch 3 layers, with input to output dimensions:
[8 4 2 1]
# of interactions
8
mlp bot arch 2 layers, with input to output dimensions:
[4 3 2]
# of features (sparse and dense)
4
dense feature size
4
sparse feature size
2
# of embeddings (= # of sparse features) 3, with dimensions 2x:
[4 3 2]
data (inputs and targets):
mini-batch: 0
[[0.69647 0.28614 0.22685 0.55131]]
[[3], [1], [1]]
[[1, 2, 3], [1], [1]]
[[0.43857]]
initial parameters (weights and bias):
[[-0.44032 -0.10196]
 [ 0.238   -0.31751]
 [-0.32455  0.03155]
 [ 0.03183  0.1344 ]]
[[ 0.40349  0.25918]
 [ 0.1282   0.25686]
 [-0.20443 -0.15959]]
[[-0.38429 -0.29173]
 [ 0.18523 -0.57685]]
[[-0.99188 -0.95116 -1.47006 -0.12516]
 [-0.37202 -0.94831  1.26233  0.0187 ]
 [-0.18422 -0.38755  0.55569 -0.12921]]
[-0.06519 -0.9588   0.00782]
[[ 0.21337 -0.58605  0.1744 ]
 [ 0.23455  0.7427  -1.28533]]
[ 0.4119  -0.50995]
[[-0.69501  0.31339  0.15133  0.8473   0.05216  0.7348   0.50556  0.37304]
 [ 0.19035  0.05105 -0.08069 -0.29722 -0.24916 -0.35642  0.06388  0.11698]
 [ 0.35424  0.51746  0.86052 -0.09638 -0.09475 -0.44015  0.47487  0.21331]
 [ 0.75296  0.28396 -0.07417 -0.17239  0.41303 -0.02725 -0.06371  0.64645]]
[-0.3933   0.25578  0.72072 -0.41845]
[[ 0.26551 -0.82371 -0.32143  0.10383]
 [-1.23811 -0.41979  0.17749 -0.22375]]
[-0.56818  0.66397]
[[0.35748 0.9317 ]]
[0.17145]
time/loss/accuracy (if enabled):
Finished training it 1/1 of epoch 0, -1.00 ms/it, loss 0.064370, accuracy 0.000 %
updated parameters (weights and bias):
[[-0.44032 -0.10196]
 [ 0.237   -0.3174 ]
 [-0.32554  0.03166]
 [ 0.03083  0.13451]]
[[ 0.40349  0.25918]
 [ 0.12782  0.25692]
 [-0.20443 -0.15959]]
[[-0.38429 -0.29173]
 [ 0.18498 -0.57673]]
[[-0.99188 -0.95116 -1.47006 -0.12516]
 [-0.37202 -0.94831  1.26233  0.0187 ]
 [-0.18422 -0.38755  0.55569 -0.12921]]
[-0.06519 -0.9588   0.00782]
[[ 0.21337 -0.58605  0.1744 ]
 [ 0.23455  0.7427  -1.28533]]
[ 0.4119  -0.50995]
[[-0.69501  0.31339  0.15133  0.8473   0.05216  0.7348   0.50556  0.37304]
 [ 0.19209  0.05105 -0.08079 -0.297   -0.24935 -0.3561   0.0642   0.11646]
 [ 0.35351  0.51746  0.86056 -0.09648 -0.09466 -0.44028  0.47473  0.21353]
 [ 0.75296  0.28396 -0.07417 -0.17239  0.41303 -0.02725 -0.06371  0.64645]]
[-0.3933   0.26001  0.71893 -0.41845]
[[ 0.26551 -0.82371 -0.32143  0.10383]
 [-1.23811 -0.42276  0.1692  -0.22375]]
[-0.56818  0.65389]
[[0.35748 0.92428]]
[0.16064]
